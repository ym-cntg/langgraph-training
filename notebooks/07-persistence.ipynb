{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Topic 7: Persistence and Checkpointing\n",
        "\n",
        "Learn how to build stateful applications that remember conversations, survive restarts, and resume interrupted workflows.\n",
        "\n",
        "## What is Persistence?\n",
        "\n",
        "Persistence in LangGraph allows your graphs to:\n",
        "- **Remember conversations** across multiple interactions\n",
        "- **Resume workflows** after interruptions or crashes\n",
        "- **Time travel** through previous states for debugging\n",
        "- **Enable human-in-the-loop** patterns with approval workflows\n",
        "\n",
        "### Why Does This Matter?\n",
        "\n",
        "Imagine building:\n",
        "- A chatbot that remembers what you discussed yesterday\n",
        "- A multi-step workflow that can pause and resume\n",
        "- An agent that waits for human approval before proceeding\n",
        "- A system that can rollback to previous states if something goes wrong\n",
        "\n",
        "All of this requires persistence!\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Understand checkpoint-based persistence\n",
        "- Use MemorySaver for in-memory state storage\n",
        "- Build stateful chatbots with conversation memory\n",
        "- Resume interrupted workflows\n",
        "- Implement human-in-the-loop patterns\n",
        "- Navigate through execution history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
        "\n",
        "model = ChatAnthropic(model=\"claude-sonnet-4-20250514\")\n",
        "print(\"âœ“ Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## Understanding Checkpoints\n",
        "\n",
        "A **checkpoint** is a snapshot of your graph's state at a specific point in time.\n",
        "\n",
        "### How Checkpointing Works\n",
        "\n",
        "```\n",
        "Execution Flow:\n",
        "[Start] â†’ [Node 1] â†’ [Checkpoint 1] â†’ [Node 2] â†’ [Checkpoint 2] â†’ [End]\n",
        "           â†“                           â†“\n",
        "         Saved                      Saved\n",
        "```\n",
        "\n",
        "Each checkpoint saves:\n",
        "- Current state values\n",
        "- Which node just executed\n",
        "- What node comes next\n",
        "- Complete execution history\n",
        "\n",
        "### MemorySaver: Your First Checkpointer\n",
        "\n",
        "MemorySaver is LangGraph's built-in checkpointer that stores state in memory. It's perfect for:\n",
        "- Development and testing\n",
        "- Single-session applications\n",
        "- Learning how persistence works\n",
        "\n",
        "**Note**: MemorySaver data is lost when your program stops. For production, you'd use SqliteSaver or a custom database-backed checkpointer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Example 1: Stateful Chatbot with Memory\n",
        "\n",
        "Let's build a chatbot that remembers your conversation across multiple interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for our chatbot\n",
        "class ChatState(TypedDict):\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "# Create a simple chatbot node\n",
        "def chatbot_node(state: ChatState):\n",
        "    \"\"\"Process messages and generate a response.\"\"\"\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "print(\"âœ“ Chatbot node created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the graph WITH persistence\n",
        "graph_builder = StateGraph(ChatState)\n",
        "\n",
        "# Add the chatbot node\n",
        "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
        "\n",
        "# Add edges\n",
        "graph_builder.add_edge(START, \"chatbot\")\n",
        "graph_builder.add_edge(\"chatbot\", END)\n",
        "\n",
        "# â­ The magic happens here: add a checkpointer!\n",
        "memory = MemorySaver()\n",
        "chatbot_graph = graph_builder.compile(checkpointer=memory)\n",
        "\n",
        "print(\"âœ“ Chatbot graph compiled with persistence!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-6",
      "metadata": {},
      "source": [
        "### Using Thread IDs for Multiple Conversations\n",
        "\n",
        "Each conversation needs a unique **thread_id** to keep conversations separate.\n",
        "\n",
        "Think of thread_id as:\n",
        "- A conversation ID\n",
        "- A session identifier\n",
        "- A user ID for multi-user systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for this conversation thread\n",
        "config = {\"configurable\": {\"thread_id\": \"conversation-1\"}}\n",
        "\n",
        "# First message in our conversation\n",
        "print(\"\\nğŸ’¬ Message 1:\")\n",
        "print(\"User: Hi! My name is Alice and I love Python programming.\\n\")\n",
        "\n",
        "result = chatbot_graph.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Hi! My name is Alice and I love Python programming.\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Second message - same thread_id!\n",
        "print(\"\\nğŸ’¬ Message 2:\")\n",
        "print(\"User: What's my name?\\n\")\n",
        "\n",
        "result = chatbot_graph.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
        "    config=config  # Same thread_id as before!\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ“ The chatbot remembered your name from the previous message!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Third message - testing deeper memory\n",
        "print(\"\\nğŸ’¬ Message 3:\")\n",
        "print(\"User: What programming language did I mention?\\n\")\n",
        "\n",
        "result = chatbot_graph.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What programming language did I mention?\")]},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ“ Complete conversation history is maintained!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "### Multiple Concurrent Conversations\n",
        "\n",
        "You can maintain separate conversations using different thread IDs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start a completely separate conversation\n",
        "config_bob = {\"configurable\": {\"thread_id\": \"conversation-2\"}}\n",
        "\n",
        "print(\"\\nğŸ’¬ Different conversation (thread-2):\")\n",
        "print(\"User: Hello! My name is Bob and I work with JavaScript.\\n\")\n",
        "\n",
        "result = chatbot_graph.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Hello! My name is Bob and I work with JavaScript.\")]},\n",
        "    config=config_bob\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ask the same question in Bob's conversation\n",
        "print(\"\\nğŸ’¬ Same question, different thread:\")\n",
        "print(\"User: What's my name?\\n\")\n",
        "\n",
        "result = chatbot_graph.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"What's my name?\")]},\n",
        "    config=config_bob\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ“ This conversation knows about Bob, not Alice!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Return to Alice's conversation\n",
        "print(\"\\nğŸ’¬ Back to Alice's conversation (thread-1):\")\n",
        "print(\"User: Remind me what we talked about.\\n\")\n",
        "\n",
        "result = chatbot_graph.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Remind me what we talked about.\")]},\n",
        "    config=config  # Back to thread-1\n",
        ")\n",
        "\n",
        "print(f\"Assistant: {result['messages'][-1].content}\")\n",
        "print(\"\\nâœ“ Alice's conversation history is intact!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "## Inspecting Conversation History\n",
        "\n",
        "You can retrieve the complete state of any conversation using `get_state()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the current state of Alice's conversation\n",
        "state = chatbot_graph.get_state(config)\n",
        "\n",
        "print(\"\\nğŸ“Š Conversation State for thread-1:\")\n",
        "print(f\"\\nNumber of messages: {len(state.values['messages'])}\")\n",
        "print(f\"\\nConversation history:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, msg in enumerate(state.values['messages'], 1):\n",
        "    role = \"User\" if isinstance(msg, HumanMessage) else \"Assistant\"\n",
        "    content = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n",
        "    print(f\"\\n{i}. {role}: {content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## Example 2: Multi-Step Workflow with Interruption\n",
        "\n",
        "Let's build a content approval workflow that can be interrupted and resumed:\n",
        "\n",
        "```\n",
        "Flow:\n",
        "[Start] â†’ [Generate Content] â†’ [INTERRUPT] â†’ [Approve/Reject] â†’ [Publish] â†’ [End]\n",
        "                                    â†‘\n",
        "                              Wait for human\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from typing import Literal\n",
        "\n",
        "# Define workflow state\n",
        "class WorkflowState(TypedDict):\n",
        "    topic: str\n",
        "    content: str\n",
        "    approved: bool\n",
        "    published: bool\n",
        "    feedback: str\n",
        "\n",
        "def generate_content(state: WorkflowState):\n",
        "    \"\"\"Generate initial content.\"\"\"\n",
        "    print(f\"\\nğŸ“ Generating content about: {state['topic']}\")\n",
        "    \n",
        "    prompt = f\"Write a brief, engaging paragraph about {state['topic']}. Keep it under 100 words.\"\n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    return {\n",
        "        \"content\": response.content,\n",
        "        \"approved\": False,\n",
        "        \"published\": False,\n",
        "        \"feedback\": \"\"\n",
        "    }\n",
        "\n",
        "def check_approval(state: WorkflowState) -> Literal[\"approved\", \"needs_revision\"]:\n",
        "    \"\"\"Route based on approval status.\"\"\"\n",
        "    return \"approved\" if state.get(\"approved\", False) else \"needs_revision\"\n",
        "\n",
        "def publish_content(state: WorkflowState):\n",
        "    \"\"\"Publish the approved content.\"\"\"\n",
        "    print(\"\\nâœ… Publishing content...\")\n",
        "    return {\"published\": True}\n",
        "\n",
        "def request_revision(state: WorkflowState):\n",
        "    \"\"\"Handle revision request.\"\"\"\n",
        "    print(\"\\nğŸ”„ Revision requested. Generating improved version...\")\n",
        "    \n",
        "    prompt = f\"\"\"Improve this content based on the feedback:\n",
        "\n",
        "ORIGINAL:\n",
        "{state['content']}\n",
        "\n",
        "FEEDBACK:\n",
        "{state['feedback']}\n",
        "\n",
        "Provide an improved version.\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    return {\n",
        "        \"content\": response.content,\n",
        "        \"approved\": False,\n",
        "        \"feedback\": \"\"\n",
        "    }\n",
        "\n",
        "print(\"âœ“ Workflow nodes defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the workflow graph\n",
        "workflow_builder = StateGraph(WorkflowState)\n",
        "\n",
        "# Add nodes\n",
        "workflow_builder.add_node(\"generate\", generate_content)\n",
        "workflow_builder.add_node(\"publish\", publish_content)\n",
        "workflow_builder.add_node(\"revise\", request_revision)\n",
        "\n",
        "# Add edges\n",
        "workflow_builder.add_edge(START, \"generate\")\n",
        "workflow_builder.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    check_approval,\n",
        "    {\n",
        "        \"approved\": \"publish\",\n",
        "        \"needs_revision\": END  # Pause here for human review\n",
        "    }\n",
        ")\n",
        "workflow_builder.add_conditional_edges(\n",
        "    \"revise\",\n",
        "    check_approval,\n",
        "    {\n",
        "        \"approved\": \"publish\",\n",
        "        \"needs_revision\": END  # Pause again if needed\n",
        "    }\n",
        ")\n",
        "workflow_builder.add_edge(\"publish\", END)\n",
        "\n",
        "# Compile with checkpointer\n",
        "workflow_memory = MemorySaver()\n",
        "workflow_graph = workflow_builder.compile(checkpointer=workflow_memory)\n",
        "\n",
        "print(\"âœ“ Workflow graph compiled with persistence!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-19",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the workflow\n",
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(workflow_graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    print(\"Graph structure:\")\n",
        "    print(\"START -> generate -> [approved?]\")\n",
        "    print(\"                      â”œâ”€ Yes -> publish -> END\")\n",
        "    print(\"                      â””â”€ No -> END (wait for human)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start the workflow\n",
        "workflow_config = {\"configurable\": {\"thread_id\": \"workflow-1\"}}\n",
        "\n",
        "print(\"\\nğŸš€ Starting content generation workflow...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = workflow_graph.invoke(\n",
        "    {\n",
        "        \"topic\": \"The benefits of LangGraph for building AI applications\",\n",
        "        \"content\": \"\",\n",
        "        \"approved\": False,\n",
        "        \"published\": False,\n",
        "        \"feedback\": \"\"\n",
        "    },\n",
        "    config=workflow_config\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“„ Generated Content:\")\n",
        "print(\"=\" * 60)\n",
        "print(result['content'])\n",
        "print(\"\\nâ¸ï¸  Workflow paused - waiting for approval...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the current state to see where we are\n",
        "current_state = workflow_graph.get_state(workflow_config)\n",
        "\n",
        "print(\"\\nğŸ“Š Current Workflow State:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Next node to execute: {current_state.next}\")\n",
        "print(f\"Content generated: {bool(current_state.values['content'])}\")\n",
        "print(f\"Approved: {current_state.values['approved']}\")\n",
        "print(f\"Published: {current_state.values['published']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-22",
      "metadata": {},
      "source": [
        "### Scenario 1: Approve the Content\n",
        "\n",
        "Let's approve the content and resume the workflow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-23",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update the state to approve the content\n",
        "print(\"\\nâœ… Approving content...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Update state with approval\n",
        "workflow_graph.update_state(\n",
        "    workflow_config,\n",
        "    {\"approved\": True}\n",
        ")\n",
        "\n",
        "# Resume workflow - pass None to continue from checkpoint\n",
        "result = workflow_graph.invoke(None, config=workflow_config)\n",
        "\n",
        "print(\"\\nâœ“ Workflow resumed and completed!\")\n",
        "print(f\"Published: {result['published']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-24",
      "metadata": {},
      "source": [
        "### Scenario 2: Request Revision\n",
        "\n",
        "Let's try the workflow again but request changes this time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-25",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start a new workflow\n",
        "workflow_config_2 = {\"configurable\": {\"thread_id\": \"workflow-2\"}}\n",
        "\n",
        "print(\"\\nğŸš€ Starting new workflow...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "result = workflow_graph.invoke(\n",
        "    {\n",
        "        \"topic\": \"The importance of checkpointing in AI systems\",\n",
        "        \"content\": \"\",\n",
        "        \"approved\": False,\n",
        "        \"published\": False,\n",
        "        \"feedback\": \"\"\n",
        "    },\n",
        "    config=workflow_config_2\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“„ Generated Content:\")\n",
        "print(\"=\" * 60)\n",
        "print(result['content'])\n",
        "print(\"\\nâ¸ï¸  Workflow paused...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-26",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Request revisions with feedback\n",
        "print(\"\\nğŸ”„ Requesting revision...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "workflow_graph.update_state(\n",
        "    workflow_config_2,\n",
        "    {\n",
        "        \"approved\": False,\n",
        "        \"feedback\": \"Please add a specific example and make it more concise.\"\n",
        "    },\n",
        "    as_node=\"revise\"  # Resume at the revise node\n",
        ")\n",
        "\n",
        "# Continue execution\n",
        "result = workflow_graph.invoke(None, config=workflow_config_2)\n",
        "\n",
        "print(\"\\nğŸ“„ Revised Content:\")\n",
        "print(\"=\" * 60)\n",
        "print(result['content'])\n",
        "print(\"\\nâ¸ï¸  Workflow paused again for re-approval...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-27",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now approve and complete\n",
        "print(\"\\nâœ… Approving revised content...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "workflow_graph.update_state(\n",
        "    workflow_config_2,\n",
        "    {\"approved\": True}\n",
        ")\n",
        "\n",
        "result = workflow_graph.invoke(None, config=workflow_config_2)\n",
        "\n",
        "print(\"\\nâœ“ Workflow completed!\")\n",
        "print(f\"Final state - Published: {result['published']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-28",
      "metadata": {},
      "source": [
        "## Time Travel: Navigating Execution History\n",
        "\n",
        "One powerful feature of checkpointing is the ability to view and restore previous states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-29",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the complete history of a workflow\n",
        "print(\"\\nğŸ“œ Execution History for workflow-2:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "history = list(workflow_graph.get_state_history(workflow_config_2))\n",
        "\n",
        "print(f\"\\nTotal checkpoints: {len(history)}\\n\")\n",
        "\n",
        "for i, state in enumerate(history[:5], 1):  # Show first 5 checkpoints\n",
        "    print(f\"{i}. Checkpoint ID: {state.config['configurable']['checkpoint_id'][:8]}...\")\n",
        "    print(f\"   Next: {state.next}\")\n",
        "    print(f\"   Approved: {state.values.get('approved', False)}\")\n",
        "    print(f\"   Published: {state.values.get('published', False)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replay from a specific checkpoint\n",
        "if len(history) >= 2:\n",
        "    print(\"\\nâ®ï¸  Demonstrating replay from earlier checkpoint...\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Get a checkpoint from history (the second one)\n",
        "    earlier_checkpoint = history[1]\n",
        "    \n",
        "    print(f\"\\nReplaying from checkpoint: {earlier_checkpoint.config['configurable']['checkpoint_id'][:8]}...\")\n",
        "    print(f\"State at that point:\")\n",
        "    print(f\"  - Approved: {earlier_checkpoint.values.get('approved', False)}\")\n",
        "    print(f\"  - Published: {earlier_checkpoint.values.get('published', False)}\")\n",
        "    print(f\"  - Next node: {earlier_checkpoint.next}\")\n",
        "    print(\"\\nâœ“ You can resume execution from any checkpoint!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-31",
      "metadata": {},
      "source": [
        "## Example 3: Research Task with Resumable Steps\n",
        "\n",
        "Let's build a research workflow that can be interrupted and resumed at any step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-32",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResearchState(TypedDict):\n",
        "    topic: str\n",
        "    research_plan: str\n",
        "    findings: str\n",
        "    summary: str\n",
        "    completed_steps: list[str]\n",
        "\n",
        "def plan_research(state: ResearchState):\n",
        "    \"\"\"Create a research plan.\"\"\"\n",
        "    print(\"\\nğŸ“‹ Planning research...\")\n",
        "    \n",
        "    prompt = f\"Create a brief research plan for: {state['topic']}. List 3 key areas to investigate.\"\n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    completed = state.get('completed_steps', [])\n",
        "    completed.append('plan')\n",
        "    \n",
        "    return {\n",
        "        \"research_plan\": response.content,\n",
        "        \"completed_steps\": completed\n",
        "    }\n",
        "\n",
        "def conduct_research(state: ResearchState):\n",
        "    \"\"\"Simulate conducting research.\"\"\"\n",
        "    print(\"\\nğŸ”¬ Conducting research...\")\n",
        "    \n",
        "    prompt = f\"\"\"Based on this research plan, provide key findings:\n",
        "\n",
        "PLAN:\n",
        "{state['research_plan']}\n",
        "\n",
        "Provide 3-4 key findings.\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    completed = state.get('completed_steps', [])\n",
        "    completed.append('research')\n",
        "    \n",
        "    return {\n",
        "        \"findings\": response.content,\n",
        "        \"completed_steps\": completed\n",
        "    }\n",
        "\n",
        "def summarize_research(state: ResearchState):\n",
        "    \"\"\"Create final summary.\"\"\"\n",
        "    print(\"\\nğŸ“Š Summarizing findings...\")\n",
        "    \n",
        "    prompt = f\"\"\"Summarize these research findings in 2-3 sentences:\n",
        "\n",
        "FINDINGS:\n",
        "{state['findings']}\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    completed = state.get('completed_steps', [])\n",
        "    completed.append('summarize')\n",
        "    \n",
        "    return {\n",
        "        \"summary\": response.content,\n",
        "        \"completed_steps\": completed\n",
        "    }\n",
        "\n",
        "print(\"âœ“ Research nodes defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-33",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the research graph\n",
        "research_builder = StateGraph(ResearchState)\n",
        "\n",
        "research_builder.add_node(\"plan\", plan_research)\n",
        "research_builder.add_node(\"research\", conduct_research)\n",
        "research_builder.add_node(\"summarize\", summarize_research)\n",
        "\n",
        "research_builder.add_edge(START, \"plan\")\n",
        "research_builder.add_edge(\"plan\", \"research\")\n",
        "research_builder.add_edge(\"research\", \"summarize\")\n",
        "research_builder.add_edge(\"summarize\", END)\n",
        "\n",
        "# Compile with persistence\n",
        "research_memory = MemorySaver()\n",
        "research_graph = research_builder.compile(checkpointer=research_memory)\n",
        "\n",
        "print(\"âœ“ Research graph compiled!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-34",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start research (but we'll \"interrupt\" it)\n",
        "research_config = {\"configurable\": {\"thread_id\": \"research-1\"}}\n",
        "\n",
        "print(\"\\nğŸš€ Starting research workflow...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Run just the first step\n",
        "for event in research_graph.stream(\n",
        "    {\n",
        "        \"topic\": \"The impact of AI agents on software development\",\n",
        "        \"research_plan\": \"\",\n",
        "        \"findings\": \"\",\n",
        "        \"summary\": \"\",\n",
        "        \"completed_steps\": []\n",
        "    },\n",
        "    config=research_config,\n",
        "    stream_mode=\"values\"\n",
        "):\n",
        "    if event.get('completed_steps'):\n",
        "        print(f\"\\nâœ“ Completed steps: {event['completed_steps']}\")\n",
        "        \n",
        "        # Simulate interruption after plan\n",
        "        if 'plan' in event['completed_steps'] and len(event['completed_steps']) == 1:\n",
        "            print(\"\\nâš ï¸  Simulating interruption (e.g., server restart)...\")\n",
        "            print(\"=\" * 60)\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-35",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check the state after interruption\n",
        "print(\"\\nğŸ“Š Checking state after interruption...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "interrupted_state = research_graph.get_state(research_config)\n",
        "\n",
        "print(f\"\\nCompleted steps: {interrupted_state.values['completed_steps']}\")\n",
        "print(f\"Next step: {interrupted_state.next}\")\n",
        "print(f\"\\nResearch plan exists: {bool(interrupted_state.values['research_plan'])}\")\n",
        "print(f\"Findings exist: {bool(interrupted_state.values['findings'])}\")\n",
        "print(f\"Summary exists: {bool(interrupted_state.values['summary'])}\")\n",
        "\n",
        "print(\"\\nâœ“ State is persisted! We can resume from here.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-36",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Resume the workflow from where it left off\n",
        "print(\"\\nğŸ”„ Resuming workflow...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Pass None to continue from checkpoint\n",
        "final_result = research_graph.invoke(None, config=research_config)\n",
        "\n",
        "print(\"\\nâœ… Research completed!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nCompleted steps: {final_result['completed_steps']}\")\n",
        "print(f\"\\nğŸ“Š Final Summary:\")\n",
        "print(final_result['summary'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-37",
      "metadata": {},
      "source": [
        "## Best Practices for Persistence\n",
        "\n",
        "### 1. Choose the Right Checkpointer\n",
        "\n",
        "```python\n",
        "# Development: MemorySaver (data lost on restart)\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "memory = MemorySaver()\n",
        "\n",
        "# Production: SqliteSaver (persists to disk)\n",
        "from langgraph.checkpoint.sqlite import SqliteSaver\n",
        "checkpointer = SqliteSaver.from_conn_string(\"checkpoints.db\")\n",
        "\n",
        "# Enterprise: PostgresSaver (scalable, multi-user)\n",
        "from langgraph.checkpoint.postgres import PostgresSaver\n",
        "checkpointer = PostgresSaver.from_conn_string(\"postgresql://...\")\n",
        "```\n",
        "\n",
        "### 2. Use Meaningful Thread IDs\n",
        "\n",
        "```python\n",
        "# âŒ Bad: Generic IDs\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# âœ… Good: Descriptive IDs\n",
        "config = {\"configurable\": {\"thread_id\": f\"user-{user_id}-session-{session_id}\"}}\n",
        "```\n",
        "\n",
        "### 3. Handle State Updates Carefully\n",
        "\n",
        "```python\n",
        "# âŒ Bad: Overwriting entire state\n",
        "graph.update_state(config, new_state)  # Loses other fields\n",
        "\n",
        "# âœ… Good: Partial updates\n",
        "graph.update_state(config, {\"approved\": True})  # Only updates one field\n",
        "```\n",
        "\n",
        "### 4. Design for Interruption\n",
        "\n",
        "```python\n",
        "# âœ… Good: Track progress\n",
        "class State(TypedDict):\n",
        "    data: str\n",
        "    completed_steps: list[str]  # Track what's done\n",
        "    current_step: str            # Track where we are\n",
        "\n",
        "def my_node(state):\n",
        "    # Do work\n",
        "    result = process_data(state['data'])\n",
        "    \n",
        "    # Update progress\n",
        "    completed = state.get('completed_steps', [])\n",
        "    completed.append('processing')\n",
        "    \n",
        "    return {\n",
        "        \"data\": result,\n",
        "        \"completed_steps\": completed\n",
        "    }\n",
        "```\n",
        "\n",
        "### 5. Clean Up Old Checkpoints\n",
        "\n",
        "```python\n",
        "# Implement cleanup for long-running applications\n",
        "import time\n",
        "\n",
        "def cleanup_old_threads(checkpointer, max_age_days=7):\n",
        "    \"\"\"Remove checkpoints older than max_age_days.\"\"\"\n",
        "    # Implementation depends on your checkpointer type\n",
        "    pass\n",
        "```\n",
        "\n",
        "### 6. Test Resume Scenarios\n",
        "\n",
        "```python\n",
        "# Always test that your graph can resume correctly\n",
        "def test_resume():\n",
        "    config = {\"configurable\": {\"thread_id\": \"test-1\"}}\n",
        "    \n",
        "    # Start workflow\n",
        "    graph.invoke(initial_state, config=config)\n",
        "    \n",
        "    # Get state\n",
        "    state = graph.get_state(config)\n",
        "    assert state.next is not None\n",
        "    \n",
        "    # Resume\n",
        "    result = graph.invoke(None, config=config)\n",
        "    assert result['completed'] == True\n",
        "```\n",
        "\n",
        "### 7. Use Checkpoints for Debugging\n",
        "\n",
        "```python\n",
        "# View execution history to debug issues\n",
        "history = list(graph.get_state_history(config))\n",
        "\n",
        "for i, state in enumerate(history):\n",
        "    print(f\"Step {i}: {state.next}\")\n",
        "    print(f\"Values: {state.values}\")\n",
        "    print()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-38",
      "metadata": {},
      "source": [
        "## Common Patterns\n",
        "\n",
        "### Pattern 1: Human-in-the-Loop Approval\n",
        "\n",
        "```python\n",
        "def needs_approval(state) -> Literal[\"approved\", \"pending\"]:\n",
        "    return \"approved\" if state.get(\"approved\") else \"pending\"\n",
        "\n",
        "# Add conditional that stops at approval\n",
        "graph.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    needs_approval,\n",
        "    {\n",
        "        \"approved\": \"continue_workflow\",\n",
        "        \"pending\": END  # Pause here\n",
        "    }\n",
        ")\n",
        "\n",
        "# Later, resume with approval\n",
        "graph.update_state(config, {\"approved\": True})\n",
        "graph.invoke(None, config=config)\n",
        "```\n",
        "\n",
        "### Pattern 2: Progress Tracking\n",
        "\n",
        "```python\n",
        "class ProgressState(TypedDict):\n",
        "    steps_completed: int\n",
        "    total_steps: int\n",
        "    current_task: str\n",
        "\n",
        "def show_progress(state):\n",
        "    progress = (state['steps_completed'] / state['total_steps']) * 100\n",
        "    print(f\"Progress: {progress:.1f}% - {state['current_task']}\")\n",
        "```\n",
        "\n",
        "### Pattern 3: Retry with Checkpoint\n",
        "\n",
        "```python\n",
        "def resilient_node(state):\n",
        "    try:\n",
        "        return process_data(state)\n",
        "    except Exception as e:\n",
        "        # State is automatically checkpointed\n",
        "        # You can retry from the same point\n",
        "        return {\"error\": str(e), \"retry_count\": state.get('retry_count', 0) + 1}\n",
        "\n",
        "def should_retry(state) -> Literal[\"retry\", \"fail\"]:\n",
        "    return \"retry\" if state.get('retry_count', 0) < 3 else \"fail\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-39",
      "metadata": {},
      "source": [
        "## Exercise 1: Build a Multi-User Chat System\n",
        "\n",
        "Create a chatbot that can handle multiple users simultaneously, each with their own conversation history.\n",
        "\n",
        "Requirements:\n",
        "1. Each user has a separate thread_id\n",
        "2. Users can have ongoing conversations\n",
        "3. Conversation history is maintained across interactions\n",
        "4. Implement a way to view conversation history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-40",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here!\n",
        "\n",
        "# TODO: Define a ChatState with messages\n",
        "\n",
        "# TODO: Create a chatbot node\n",
        "\n",
        "# TODO: Build and compile the graph with MemorySaver\n",
        "\n",
        "# TODO: Simulate conversations with 2-3 different users\n",
        "\n",
        "# TODO: Show that each user's history is kept separate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-41",
      "metadata": {},
      "source": [
        "## Exercise 2: Implement a Pausable Task Pipeline\n",
        "\n",
        "Create a data processing pipeline that:\n",
        "1. Reads data (simulated)\n",
        "2. Processes data (simulated)\n",
        "3. Validates results (simulated)\n",
        "4. Saves results (simulated)\n",
        "\n",
        "Requirements:\n",
        "- Use checkpointing to track progress\n",
        "- Add a manual approval step after validation\n",
        "- Allow the workflow to be paused and resumed\n",
        "- Track which steps have been completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here!\n",
        "\n",
        "# TODO: Define a PipelineState with fields for each step\n",
        "\n",
        "# TODO: Create nodes for read, process, validate, save\n",
        "\n",
        "# TODO: Add a conditional edge that pauses after validation\n",
        "\n",
        "# TODO: Build the graph with checkpointing\n",
        "\n",
        "# TODO: Run the pipeline, pause it, and then resume\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-43",
      "metadata": {},
      "source": [
        "## Exercise 3: Checkpoint History Explorer\n",
        "\n",
        "Create a utility that:\n",
        "1. Executes a multi-step workflow\n",
        "2. Retrieves the complete checkpoint history\n",
        "3. Displays the state at each checkpoint\n",
        "4. Allows \"replaying\" from a specific checkpoint\n",
        "\n",
        "This will help you understand how checkpoint history works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-44",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here!\n",
        "\n",
        "# TODO: Create a simple 3-step workflow\n",
        "\n",
        "# TODO: Run it completely\n",
        "\n",
        "# TODO: Use get_state_history() to retrieve all checkpoints\n",
        "\n",
        "# TODO: Display information about each checkpoint\n",
        "\n",
        "# TODO: Show how to replay from a specific checkpoint\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-45",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "1. âœ… What persistence and checkpointing are in LangGraph\n",
        "2. âœ… How to use MemorySaver for in-memory state persistence\n",
        "3. âœ… Building stateful chatbots that remember conversations\n",
        "4. âœ… Creating workflows that can be interrupted and resumed\n",
        "5. âœ… Using thread_ids to manage multiple concurrent conversations\n",
        "6. âœ… Implementing human-in-the-loop approval patterns\n",
        "7. âœ… Navigating through checkpoint history for debugging\n",
        "8. âœ… Best practices for production persistence\n",
        "\n",
        "## When to Use Persistence\n",
        "\n",
        "Use checkpointing when you need:\n",
        "- **Conversation memory** - Chatbots that remember context\n",
        "- **Long-running workflows** - Tasks that take minutes or hours\n",
        "- **Human approval** - Workflows that pause for human input\n",
        "- **Fault tolerance** - Resume after crashes or restarts\n",
        "- **Multi-session interactions** - Users returning to continue tasks\n",
        "- **Debugging** - Inspect execution history and state evolution\n",
        "\n",
        "## Production Considerations\n",
        "\n",
        "For production applications:\n",
        "1. Use **SqliteSaver** or **PostgresSaver** instead of MemorySaver\n",
        "2. Implement **checkpoint cleanup** to manage storage\n",
        "3. Add **error handling** for checkpoint operations\n",
        "4. Consider **security** - who can access which threads?\n",
        "5. Monitor **checkpoint size** - large states can impact performance\n",
        "6. Implement **backup strategies** for critical workflows\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "You've now mastered persistence in LangGraph! This is a crucial capability for building production-grade AI applications.\n",
        "\n",
        "Continue exploring:\n",
        "- **Database-backed persistence** with SqliteSaver\n",
        "- **Streaming with checkpoints** for real-time updates\n",
        "- **Complex multi-agent systems** with persistent state\n",
        "- **Human-in-the-loop patterns** for AI safety\n",
        "\n",
        "Congratulations on completing the Persistence module!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
