{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 2: Basic Graphs\n",
    "\n",
    "Now that you understand the fundamentals, let's build more sophisticated graphs with multiple nodes and complex state management.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Create graphs with multiple nodes\n",
    "- Manage state transformations\n",
    "- Build linear workflows\n",
    "- Pass data between nodes effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "import os\n",
    "import getpass\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-sonnet-4-20250514\")\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Content Creation Pipeline\n",
    "\n",
    "Let's build a multi-step content creation workflow that:\n",
    "1. Generates a topic outline\n",
    "2. Writes content based on the outline\n",
    "3. Reviews and improves the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ ContentState defined\n"
     ]
    }
   ],
   "source": [
    "# Define our state with more fields\n",
    "class ContentState(TypedDict):\n",
    "    topic: str\n",
    "    outline: str\n",
    "    content: str\n",
    "    review: str\n",
    "    final_content: str\n",
    "\n",
    "print(\"âœ“ ContentState defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Multiple Nodes\n",
    "\n",
    "Each node performs a specific task in our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All nodes created!\n"
     ]
    }
   ],
   "source": [
    "def generate_outline(state: ContentState) -> ContentState:\n",
    "    \"\"\"Generate an outline for the topic.\"\"\"\n",
    "    print(\"ðŸ“ Generating outline...\")\n",
    "    \n",
    "    prompt = f\"\"\"Create a detailed outline for a blog post about: {state['topic']}\n",
    "    \n",
    "    Include:\n",
    "    - 3-4 main sections\n",
    "    - Key points for each section\n",
    "    - Estimated word count for each section\n",
    "    \n",
    "    Keep it concise but comprehensive.\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"topic\": state[\"topic\"],\n",
    "        \"outline\": response.content,\n",
    "        \"content\": \"\",\n",
    "        \"review\": \"\",\n",
    "        \"final_content\": \"\"\n",
    "    }\n",
    "\n",
    "def write_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Write content based on the outline.\"\"\"\n",
    "    print(\"âœï¸  Writing content...\")\n",
    "    \n",
    "    prompt = f\"\"\"Based on this outline, write a blog post:\n",
    "    \n",
    "    OUTLINE:\n",
    "    {state['outline']}\n",
    "    \n",
    "    Write engaging, informative content. Keep it around 300-400 words.\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"content\": response.content\n",
    "    }\n",
    "\n",
    "def review_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Review and suggest improvements.\"\"\"\n",
    "    print(\"ðŸ” Reviewing content...\")\n",
    "    \n",
    "    prompt = f\"\"\"Review this content and provide specific suggestions for improvement:\n",
    "    \n",
    "    CONTENT:\n",
    "    {state['content']}\n",
    "    \n",
    "    Focus on:\n",
    "    - Clarity and flow\n",
    "    - Engagement\n",
    "    - Completeness\n",
    "    \n",
    "    Be specific and actionable.\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"review\": response.content\n",
    "    }\n",
    "\n",
    "def finalize_content(state: ContentState) -> ContentState:\n",
    "    \"\"\"Apply review suggestions to create final version.\"\"\"\n",
    "    print(\"âœ¨ Finalizing content...\")\n",
    "    \n",
    "    prompt = f\"\"\"Based on this review, improve the content:\n",
    "    \n",
    "    ORIGINAL CONTENT:\n",
    "    {state['content']}\n",
    "    \n",
    "    REVIEW:\n",
    "    {state['review']}\n",
    "    \n",
    "    Provide the improved version.\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"final_content\": response.content\n",
    "    }\n",
    "\n",
    "print(\"âœ“ All nodes created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph\n",
    "\n",
    "Now let's connect our nodes in a linear workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Content creation graph compiled!\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "graph_builder = StateGraph(ContentState)\n",
    "\n",
    "# Add all nodes\n",
    "graph_builder.add_node(\"generate_outline\", generate_outline)\n",
    "graph_builder.add_node(\"write_content\", write_content)\n",
    "graph_builder.add_node(\"review_content\", review_content)\n",
    "graph_builder.add_node(\"finalize_content\", finalize_content)\n",
    "\n",
    "# Add edges to create the flow\n",
    "graph_builder.add_edge(START, \"generate_outline\")\n",
    "graph_builder.add_edge(\"generate_outline\", \"write_content\")\n",
    "graph_builder.add_edge(\"write_content\", \"review_content\")\n",
    "graph_builder.add_edge(\"review_content\", \"finalize_content\")\n",
    "graph_builder.add_edge(\"finalize_content\", END)\n",
    "\n",
    "# Compile\n",
    "content_graph = graph_builder.compile()\n",
    "\n",
    "print(\"âœ“ Content creation graph compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(content_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(\"Graph structure:\")\n",
    "    print(\"START -> generate_outline -> write_content -> review_content -> finalize_content -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Pipeline\n",
    "\n",
    "Let's test our content creation pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Generating outline...\n",
      "âœï¸  Writing content...\n",
      "ðŸ” Reviewing content...\n",
      "âœ¨ Finalizing content...\n",
      "\n",
      "==================================================\n",
      "PIPELINE COMPLETE!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Run the graph\n",
    "result = content_graph.invoke({\n",
    "    \"topic\": \"How to Get Started with LangGraph\",\n",
    "    \"outline\": \"\",\n",
    "    \"content\": \"\",\n",
    "    \"review\": \"\",\n",
    "    \"final_content\": \"\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PIPELINE COMPLETE!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ OUTLINE:\n",
      "--------------------------------------------------\n",
      "# Blog Post Outline: How to Get Started with LangGraph\n",
      "\n",
      "## Introduction (200-250 words)\n",
      "- Brief explanation of what LangGraph is (LangChain's library for building stateful, multi-actor applications with LLMs)\n",
      "- Why LangGraph matters: enables complex agent workflows, cyclical flows, and human-in-the-loop patterns\n",
      "- What readers will learn from this guide\n",
      "- Prerequisites: basic Python knowledge and familiarity with LLMs\n",
      "\n",
      "## Section 1: Understanding LangGraph Fundamentals (400-500 words)\n",
      "- **Core Concepts**\n",
      "  - Graphs, nodes, and edges explained\n",
      "  - State management and how it differs from traditional chains\n",
      "  - Agent vs. tool nodes\n",
      "- **Key Components**\n",
      "  - StateGraph class and its role\n",
      "  - Message passing between nodes\n",
      "  - Conditional routing and decision points\n",
      "- **Common Use Cases**\n",
      "  - Multi-agent conversations\n",
      "  - Complex reasoning workflows\n",
      "  - Human oversight integration\n",
      "  - Iterative problem-solving patterns\n",
      "\n",
      "## Section 2: Setting Up Your Development Environment (300-400 words)\n",
      "- **Installation Requirements**\n",
      "  - Installing LangGraph via pip\n",
      "  - Required dependencies (langchain, langchain-openai, etc.)\n",
      "  - Setting up API keys for LLM providers\n",
      "- **Basic Project Structure**\n",
      "  - Recommended folder organization\n",
      "  - Configuration files and environment variables\n",
      "  - Import statements and initial setup\n",
      "- **Verification Steps**\n",
      "  - Simple \"Hello World\" graph example\n",
      "  - Testing your installation\n",
      "  - Troubleshooting common setup issues\n",
      "\n",
      "## Section 3: Building Your First LangGraph Application (600-700 words)\n",
      "- **Step-by-Step Tutorial: Creating a Research Assistant**\n",
      "  - Defining the state schema\n",
      "  - Creating individual nodes (researcher, writer, reviewer)\n",
      "  - Setting up edges and conditional logic\n",
      "  - Implementing the main graph workflow\n",
      "- **Code Walkthrough**\n",
      "  - Detailed explanation of each component\n",
      "  - How data flows between nodes\n",
      "  - Error handling and validation\n",
      "- **Testing and Debugging**\n",
      "  - Running your first graph\n",
      "  - Using built-in visualization tools\n",
      "  - Common debugging techniques\n",
      "  - Iterating and improving your workflow\n",
      "\n",
      "## Section 4: Best Practices and Next Steps (350-400 words)\n",
      "- **Development Best Practices**\n",
      "  - Designing clear state schemas\n",
      "  - Writing modular, reusable nodes\n",
      "  - Implementing proper error handling\n",
      "  - Performance optimization tips\n",
      "- **Advanced Features to Explore**\n",
      "  - Human-in-the-loop workflows\n",
      "  - Persistence and checkpointing\n",
      "  - Custom tool integration\n",
      "  - Streaming and real-time updates\n",
      "- **Resources for Continued Learning**\n",
      "  - Official documentation and examples\n",
      "  - Community resources and tutorials\n",
      "  - Sample projects and templates\n",
      "  - Integration with other LangChain components\n",
      "\n",
      "## Conclusion (150-200 words)\n",
      "- Recap of key concepts covered\n",
      "- Encouragement to experiment with different graph structures\n",
      "- Call-to-action: building readers' first custom application\n",
      "- Links to additional resources and community support\n",
      "\n",
      "---\n",
      "\n",
      "**Total Estimated Word Count: 2,000-2,450 words**\n",
      "\n",
      "**Estimated Reading Time: 8-10 minutes**\n",
      "\n",
      "**Target Audience: Developers familiar with Python and AI/LLM concepts who want to build more sophisticated agent workflows**\n"
     ]
    }
   ],
   "source": [
    "# Display the outline\n",
    "print(\"\\nðŸ“ OUTLINE:\")\n",
    "print(\"-\" * 50)\n",
    "print(result[\"outline\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœï¸  FIRST DRAFT:\n",
      "--------------------------------------------------\n",
      "# How to Get Started with LangGraph: Building Stateful AI Applications Made Simple\n",
      "\n",
      "If you've been working with large language models (LLMs), you've probably hit the limitations of simple, linear chains. What happens when you need your AI agents to collaborate, make decisions based on previous steps, or involve human oversight in complex workflows? Enter **LangGraph** â€“ LangChain's powerful library designed specifically for building stateful, multi-actor applications with LLMs.\n",
      "\n",
      "Unlike traditional chains that follow a predetermined path from input to output, LangGraph enables you to create sophisticated agent workflows with cyclical flows, conditional branching, and dynamic decision-making. Think of it as upgrading from a simple assembly line to an intelligent, adaptive network where AI agents can collaborate, iterate, and respond to changing conditions.\n",
      "\n",
      "## Why LangGraph Matters\n",
      "\n",
      "In today's AI landscape, the most valuable applications aren't just about getting a single response from an LLM. They're about orchestrating complex reasoning processes, enabling multiple specialized agents to work together, and creating workflows that can adapt and improve over time. LangGraph makes these advanced patterns accessible to developers without requiring deep expertise in distributed systems or complex state management.\n",
      "\n",
      "Whether you're building a research assistant that needs to gather information from multiple sources, a content creation pipeline with review cycles, or a customer service system with escalation workflows, LangGraph provides the foundation to make these multi-step, stateful processes both manageable and reliable.\n",
      "\n",
      "## What You'll Learn\n",
      "\n",
      "This comprehensive guide will take you from LangGraph novice to confident practitioner. You'll understand the core concepts that make LangGraph unique, set up a complete development environment, and build your first multi-agent application from scratch. We'll also cover essential best practices and point you toward advanced features for future exploration.\n",
      "\n",
      "**Prerequisites**: To get the most from this tutorial, you should have basic Python programming knowledge and some familiarity with LLMs and AI concepts. If you've used LangChain before, that's helpful but not required â€“ we'll cover everything you need to know to get started with LangGraph's unique approach to building intelligent, stateful applications.\n",
      "\n",
      "---\n",
      "\n",
      "## Understanding LangGraph Fundamentals\n",
      "\n",
      "Before diving into code, it's crucial to understand what makes LangGraph different from traditional LLM applications. At its heart, LangGraph is built around the concept of **graphs** â€“ not the mathematical charts you might be thinking of, but computational graphs that represent the flow of information and decision-making in your application.\n",
      "\n",
      "### Core Concepts\n",
      "\n",
      "**Graphs, Nodes, and Edges**: Think of a LangGraph application as a flowchart where each step is a node (representing an action or decision) connected by edges (representing the flow of information). Unlike linear chains, these graphs can have cycles, branches, and complex routing logic. A node might be an LLM call, a tool execution, or a human input step, while edges determine how information flows between these components.\n",
      "\n",
      "**State Management**: This is where LangGraph truly shines. Instead of passing data linearly from one step to the next, LangGraph maintains a shared state that all nodes can read from and write to. This means your AI agents can collaborate by updating shared information, remember previous decisions, and build upon each other's work. State management enables persistent memory across the entire workflow, something impossible with traditional chains.\n",
      "\n",
      "**Agent vs. Tool Nodes**: LangGraph distinguishes between agent nodes (which make decisions and generate responses) and tool nodes (which perform specific actions like web searches or database queries). This separation allows for cleaner architecture and more predictable behavior in complex workflows.\n",
      "\n",
      "### Key Components\n",
      "\n",
      "The **StateGraph class** serves as the foundation of every LangGraph application. It defines the structure of your shared state and orchestrates the flow between nodes. Think of it as the conductor of an orchestra, ensuring all components work together harmoniously.\n",
      "\n",
      "**Message passing** between nodes follows a structured pattern where each node receives the current state, performs its function, and returns updates to be merged back into the shared state. This creates a reliable, traceable flow of information throughout your application.\n",
      "\n",
      "**Conditional routing** allows your graphs to make intelligent decisions about what happens next. Instead of following a fixed path, nodes can examine the current state and choose different routes based on the data, enabling truly adaptive workflows.\n",
      "\n",
      "### Common Use Cases\n",
      "\n",
      "LangGraph excels in scenarios requiring **multi-agent conversations** where different AI personalities or roles need to collaborate. Imagine a brainstorming session with a creative agent, a critical reviewer, and a practical implementer all working together on a project.\n",
      "\n",
      "**Complex reasoning workflows** benefit enormously from LangGraph's iterative capabilities. Research tasks, problem-solving scenarios, and analytical processes can loop back on themselves, refining and improving results through multiple passes.\n",
      "\n",
      "**Human oversight integration** becomes seamless with LangGraph's human-in-the-loop patterns, allowing for approval steps, feedback incorporation, and manual intervention when needed, making AI applications suitable for high-stakes business environments.\n",
      "\n",
      "---\n",
      "\n",
      "## Setting Up Your Development Environment\n",
      "\n",
      "Getting started with LangGraph requires a properly configured development environment. Let's walk through the essential setup steps to ensure you're ready to build sophisticated AI applications.\n",
      "\n",
      "### Installation Requirements\n",
      "\n",
      "First, install LangGraph using pip. Open your terminal or command prompt and run:\n",
      "\n",
      "```bash\n",
      "pip install langgraph\n",
      "```\n",
      "\n",
      "LangGraph has several important dependencies that you'll likely need for most projects:\n",
      "\n",
      "```bash\n",
      "pip install langchain langchain-openai langchain-anthropic python-dotenv\n",
      "```\n",
      "\n",
      "These packages provide the core LangChain functionality, LLM integrations, and environment variable management you'll need for real-world applications.\n",
      "\n",
      "**Setting up API keys** is crucial for LLM integration. Create a `.env` file in your project root and add your API credentials:\n",
      "\n",
      "```\n",
      "OPENAI_API_KEY=your_openai_key_here\n",
      "ANTHROPIC_API_KEY=your_anthropic_key_here\n",
      "```\n",
      "\n",
      "Never commit API keys to version control â€“ always use environment variables or secure configuration management.\n",
      "\n",
      "### Basic Project Structure\n",
      "\n",
      "Organize your LangGraph projects with a clear, scalable structure:\n",
      "\n",
      "```\n",
      "my_langgraph_project/\n",
      "â”œâ”€â”€ .env\n",
      "â”œâ”€â”€ requirements.txt\n",
      "â”œâ”€â”€ main.py\n",
      "â”œâ”€â”€ nodes/\n",
      "â”‚   â”œâ”€â”€ __init__.py\n",
      "â”‚   â”œâ”€â”€ agent_nodes.py\n",
      "â”‚   â””â”€â”€ tool_nodes.py\n",
      "â”œâ”€â”€ graphs/\n",
      "â”‚   â”œâ”€â”€ __init__.py\n",
      "â”‚   â””â”€â”€ workflow.py\n",
      "â””â”€â”€ utils/\n",
      "    â”œâ”€â”€ __init__.py\n",
      "    â””â”€â”€ state.py\n",
      "```\n",
      "\n",
      "This structure separates concerns clearly: nodes contain your individual workflow steps, graphs define your overall workflows, and utils house shared utilities like state definitions.\n",
      "\n",
      "In your main Python file, start with these essential imports:\n",
      "\n",
      "```python\n",
      "import os\n",
      "from dotenv import load_dotenv\n",
      "from langgraph.graph import StateGraph\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "load_dotenv()\n",
      "```\n",
      "\n",
      "### Verification Steps\n",
      "\n",
      "Test your installation with this simple \"Hello World\" example:\n",
      "\n",
      "```python\n",
      "from langgraph.graph import StateGraph\n",
      "from typing import TypedDict\n",
      "\n",
      "class State(TypedDict):\n",
      "    message: str\n",
      "\n",
      "def hello_node(state: State) -> State:\n",
      "    return {\"message\": f\"Hello, {state['message']}!\"}\n",
      "\n",
      "# Create and test a minimal graph\n",
      "graph = StateGraph(State)\n",
      "graph.add_node(\"hello\", hello_node)\n",
      "graph.set_entry_point(\"hello\")\n",
      "graph.set_finish_point(\"hello\")\n",
      "\n",
      "app = graph.compile()\n",
      "result = app.invoke({\"message\": \"World\"})\n",
      "print(result)  # Should output: {'message': 'Hello, World!'}\n",
      "```\n",
      "\n",
      "If this runs without errors, your environment is properly configured! Common setup issues include missing API keys, incorrect Python versions, or dependency conflicts â€“ ensure you're using Python 3.8+ and consider using virtual environments to avoid package conflicts.\n",
      "\n",
      "---\n",
      "\n",
      "## Building Your First LangGraph Application\n",
      "\n",
      "Now for the exciting part â€“ building a complete LangGraph application! We'll create a research assistant that demonstrates the key concepts and patterns you'll use in more complex projects.\n",
      "\n",
      "### Step-by-Step Tutorial: Creating a Research Assistant\n",
      "\n",
      "Our research assistant will have three specialized agents: a researcher who gathers information, a writer who synthesizes findings, and a reviewer who ensures quality. Each agent will have distinct responsibilities while sharing a common state.\n",
      "\n",
      "**Defining the State Schema**\n",
      "\n",
      "First, let's define our shared state structure:\n",
      "\n",
      "```python\n",
      "from typing import TypedDict, List\n",
      "from langchain_core.messages import BaseMessage\n",
      "\n",
      "class ResearchState(TypedDict):\n",
      "    topic: str\n",
      "    research_findings: List[str]\n",
      "    draft_content: str\n",
      "    final_content: str\n",
      "    review_feedback: str\n",
      "    iteration_count: int\n",
      "    status: str\n",
      "```\n",
      "\n",
      "This state will be shared across all nodes, allowing agents to build upon each other's work.\n",
      "\n",
      "**Creating Individual Nodes**\n",
      "\n",
      "Let's implement each specialized agent:\n",
      "\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "llm = ChatOpenAI(temperature=0.7)\n",
      "\n",
      "def researcher_node(state: ResearchState) -> ResearchState:\n",
      "    \"\"\"Gather information about the research topic\"\"\"\n",
      "    prompt = f\"Research the topic: {state['topic']}. Provide 3-4 key findings.\"\n",
      "    \n",
      "    response = llm.invoke(prompt)\n",
      "    findings = response.content.split('\\n')\n",
      "    \n",
      "    return {\n",
      "        **state,\n",
      "        \"research_findings\": findings,\n",
      "        \"status\": \"research_complete\"\n",
      "    }\n",
      "\n",
      "def writer_node(state: ResearchState) -> ResearchState:\n",
      "    \"\"\"Synthesize research findings into coherent content\"\"\"\n",
      "    findings_text = '\\n'.join(state['research_findings'])\n",
      "    prompt = f\"Write a comprehensive summary based on these findings:\\n{findings_text}\"\n",
      "    \n",
      "    response = llm.invoke(prompt)\n",
      "    \n",
      "    return {\n",
      "        **state,\n",
      "        \"draft_content\": response.content,\n",
      "        \"status\": \"draft_complete\"\n",
      "    }\n",
      "\n",
      "def reviewer_node(state: ResearchState) -> ResearchState:\n",
      "    \"\"\"Review and provide feedback on the draft\"\"\"\n",
      "    prompt = f\"Review this content and provide feedback:\\n{state['draft_content']}\"\n",
      "    \n",
      "    response = llm.invoke(prompt)\n",
      "    \n",
      "    return {\n",
      "        **state,\n",
      "        \"review_feedback\": response.content,\n",
      "        \"final_content\": state['draft_content'],  # Simplified for this example\n",
      "        \"status\": \"review_complete\",\n",
      "        \"iteration_count\": state.get('iteration_count', 0) + 1\n",
      "    }\n",
      "```\n",
      "\n",
      "**Setting Up the Graph Workflow**\n",
      "\n",
      "Now let's connect these nodes into a cohesive workflow:\n",
      "\n",
      "```python\n",
      "def create_research_graph():\n",
      "    graph = StateGraph(ResearchState)\n",
      "    \n",
      "    # Add nodes\n",
      "    graph.add_node(\"researcher\", researcher_node)\n",
      "    graph.add_node(\"writer\", writer_node)\n",
      "    graph.add_node(\"reviewer\", reviewer_node)\n",
      "    \n",
      "    # Define the workflow\n",
      "    graph.set_entry_point(\"researcher\")\n",
      "    graph.add_edge(\"researcher\", \"writer\")\n",
      "    graph.add_edge(\"writer\", \"reviewer\")\n",
      "    graph.set_finish_point(\"reviewer\")\n",
      "    \n",
      "    return graph.compile()\n",
      "\n",
      "# Create and test the application\n",
      "research_app = create_research_graph()\n",
      "\n",
      "# Run the research assistant\n",
      "initial_state = {\n",
      "    \"topic\": \"The impact of artificial intelligence on education\",\n",
      "    \"research_findings\": [],\n",
      "    \"draft_content\": \"\",\n",
      "    \"final_content\": \"\",\n",
      "    \"review_feedback\": \"\",\n",
      "    \"iteration_count\": 0,\n",
      "    \"status\": \"initialized\"\n",
      "}\n",
      "\n",
      "result = research_app.invoke(initial_state)\n",
      "print(\"Final Result:\", result['final_content'])\n",
      "```\n",
      "\n",
      "### Code Walkthrough and Testing\n",
      "\n",
      "The beauty of this workflow lies in how **data flows seamlessly** between nodes. The researcher populates the `research_findings`, which the writer uses to create `draft_content`, which the reviewer then evaluates. Each node builds upon the previous work while maintaining the complete context.\n",
      "\n",
      "**Error handling** is crucial in production applications. Wrap your node functions in try-catch blocks and update the state with error information:\n",
      "\n",
      "```python\n",
      "def safe_researcher_node(state: ResearchState) -> ResearchState:\n",
      "    try:\n",
      "        return researcher_node(state)\n",
      "    except Exception as e:\n",
      "        return {**state, \"status\": f\"error: {str(e)}\"}\n",
      "```\n",
      "\n",
      "**Testing your graph** can be done incrementally. Test individual nodes first, then the complete workflow. LangGraph provides excellent debugging tools â€“ you can inspect the state at each step and visualize the execution flow.\n",
      "\n",
      "For **iteration and improvement**, consider adding conditional logic to repeat steps based on quality thresholds, or implement human-in-the-loop checkpoints where reviewers can request revisions. The stateful nature of LangGraph makes these enhancements straightforward to implement.\n",
      "\n",
      "---\n",
      "\n",
      "## Best Practices and Next Steps\n",
      "\n",
      "As you develop more sophisticated LangGraph applications, following established best practices will save you time and prevent common pitfalls.\n",
      "\n",
      "### Development Best Practices\n",
      "\n",
      "**Design clear state schemas** from the beginning. Your state structure is the foundation of your entire application â€“ make it comprehensive enough to support your workflow but not so complex that it becomes unwieldy. Use TypedDict for better IDE support and runtime validation.\n",
      "\n",
      "**Write modular, reusable nodes** by keeping each node focused on a single responsibility. This makes your code easier to test, debug, and maintain. Consider creating base classes for common node patterns and use composition to build complex behaviors.\n",
      "\n",
      "**Implement proper error handling** at every level. Nodes should gracefully handle API failures, invalid inputs, and unexpected states. Always update your state with error information so downstream nodes can respond appropriately.\n",
      "\n",
      "**Performance optimization** becomes crucial as your graphs grow. Cache expensive operations, implement timeouts for external API calls, and consider parallel execution for independent nodes. Monitor token usage and implement cost controls for production applications.\n",
      "\n",
      "### Advanced Features to Explore\n",
      "\n",
      "**Human-in-the-loop workflows** represent one of LangGraph's most powerful capabilities. You can pause execution at any point, request human input or approval, and then resume with the updated state. This is invaluable for high-stakes applications where human oversight is essential.\n",
      "\n",
      "**Persistence and checkpointing** allow your applications to survive restarts and handle long-running workflows. LangGraph can save state snapshots and resume from specific points, enabling robust, fault-tolerant applications.\n",
      "\n",
      "**Custom tool integration** extends your graphs beyond simple LLM calls. Connect to databases, APIs, file systems, and external services to create truly comprehensive workflows that bridge AI capabilities with real-world systems.\n",
      "\n",
      "**Streaming and real-time updates** provide better user experiences for long-running processes. Instead of waiting for complete results, you can stream intermediate outputs and progress updates to users.\n",
      "\n",
      "### Resources for Continued Learning\n",
      "\n",
      "The **official LangGraph documentation** provides comprehensive examples and API references. The LangChain community maintains active forums and Discord channels where you can get help and share experiences with other developers.\n",
      "\n",
      "**Sample projects and templates** available in the LangChain GitHub repository offer excellent starting points for common use cases. Study these examples to understand different architectural patterns and implementation strategies.\n",
      "\n",
      "Consider **integration with other LangChain components** like vector stores, document loaders, and specialized chains. LangGraph works seamlessly with the broader LangChain ecosystem, enabling you to leverage existing tools and patterns in your stateful workflows.\n",
      "\n",
      "---\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "LangGraph represents a significant leap forward in building sophisticated AI applications. By moving beyond simple input-output chains to stateful, collaborative workflows, you can create AI systems that truly understand context, collaborate effectively, and adapt to complex requirements.\n",
      "\n",
      "The concepts we've covered â€“ from basic graph structure and state management to building complete multi-agent workflows â€“ provide a solid foundation for your LangGraph journey. Remember that the most powerful applications often start simple and evolve through iteration and experimentation.\n",
      "\n",
      "**Your next step is clear**: take the research assistant example and modify it for your own use case. Try adding new node types, implementing conditional routing, or integrating external tools. The beauty of LangGraph lies in its flexibility â€“ there's no single \"right\" way to structure your workflows.\n",
      "\n",
      "**Start building today**. Whether you're automating business processes, creating intelligent content pipelines, or developing the next generation of AI assistants, LangGraph provides the tools to turn your vision into reality. Join the growing community of developers who are pushing the boundaries of what's possible with AI-powered applications.\n",
      "\n",
      "Ready to dive deeper? Check out the [official LangGraph documentation](https://langchain-ai.github.io/langgraph/) and connect with fellow developers in the [LangChain Discord community](https://discord.gg/langchain). Your next breakthrough is just one graph away!\n"
     ]
    }
   ],
   "source": [
    "# Display the first draft\n",
    "print(\"\\nâœï¸  FIRST DRAFT:\")\n",
    "print(\"-\" * 50)\n",
    "print(result[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” REVIEW:\n",
      "--------------------------------------------------\n",
      "# Content Review: LangGraph Tutorial\n",
      "\n",
      "## Overall Assessment\n",
      "This is a well-structured, comprehensive tutorial that effectively introduces LangGraph. The content flows logically and covers essential topics thoroughly. However, there are several areas where clarity, engagement, and completeness can be improved.\n",
      "\n",
      "## Specific Improvement Suggestions\n",
      "\n",
      "### 1. **Introduction & Hook Enhancement**\n",
      "\n",
      "**Current Issue**: The opening paragraph is dense and somewhat abstract.\n",
      "\n",
      "**Suggested Improvement**:\n",
      "```markdown\n",
      "# How to Get Started with LangGraph: Building Stateful AI Applications Made Simple\n",
      "\n",
      "Have you ever built a chatbot that couldn't remember what it said two messages ago? Or created an AI workflow that got stuck because it couldn't handle unexpected responses? You're not alone.\n",
      "\n",
      "Most AI applications today follow a simple pattern: input â†’ process â†’ output. But what if your AI needs to collaborate with other AI agents, remember previous decisions, or pause for human approval? That's where **LangGraph** comes in.\n",
      "\n",
      "LangGraph is LangChain's breakthrough library for building AI applications that think, remember, and collaborate like human teams.\n",
      "```\n",
      "\n",
      "### 2. **Technical Clarity Issues**\n",
      "\n",
      "**Problem**: The \"graphs\" explanation is confusing.\n",
      "\n",
      "**Fix**: Replace this paragraph in the \"Understanding LangGraph Fundamentals\" section:\n",
      "```markdown\n",
      "### What Are LangGraph \"Graphs\"?\n",
      "\n",
      "Don't worry â€“ we're not talking about bar charts or pie graphs! In LangGraph, a \"graph\" is like a flowchart that shows how information moves through your AI application.\n",
      "\n",
      "Imagine planning a group project:\n",
      "- **Nodes** = Team members (each with specific roles)\n",
      "- **Edges** = Communication paths between team members  \n",
      "- **State** = The shared project document everyone can read and update\n",
      "\n",
      "This is exactly how LangGraph works, but with AI agents instead of people.\n",
      "```\n",
      "\n",
      "### 3. **Code Examples Need Context**\n",
      "\n",
      "**Problem**: Code appears without sufficient explanation.\n",
      "\n",
      "**Solution**: Add setup context before each code block:\n",
      "```markdown\n",
      "### Installation and Setup\n",
      "\n",
      "Before running any code, let's get your environment ready. You'll need Python 3.8+ installed.\n",
      "\n",
      "**Step 1: Install required packages**\n",
      "```bash\n",
      "# Core LangGraph installation\n",
      "pip install langgraph\n",
      "\n",
      "# Additional dependencies for this tutorial\n",
      "pip install langchain langchain-openai python-dotenv\n",
      "```\n",
      "\n",
      "**Why these packages?**\n",
      "- `langgraph`: The main library we're learning\n",
      "- `langchain`: Provides LLM integrations\n",
      "- `langchain-openai`: Connects to OpenAI's APIs\n",
      "- `python-dotenv`: Manages environment variables securely\n",
      "```\n",
      "\n",
      "### 4. **Missing Troubleshooting Section**\n",
      "\n",
      "**Add after the verification steps**:\n",
      "```markdown\n",
      "### Common Setup Issues & Solutions\n",
      "\n",
      "**\"ModuleNotFoundError: No module named 'langgraph'\"**\n",
      "- Solution: Ensure you're in the correct virtual environment and run `pip install langgraph`\n",
      "\n",
      "**\"AuthenticationError: Invalid API key\"**\n",
      "- Solution: Check your `.env` file format and verify your API key is active\n",
      "\n",
      "**\"Graph execution hangs indefinitely\"**\n",
      "- Solution: Check for infinite loops in your graph structure\n",
      "```\n",
      "\n",
      "### 5. **Enhanced Practical Example**\n",
      "\n",
      "**Problem**: The research assistant jumps complexity levels too quickly.\n",
      "\n",
      "**Solution**: Add a simpler example first:\n",
      "```markdown\n",
      "## Your First 5-Minute LangGraph App\n",
      "\n",
      "Let's start with something simple â€“ a two-step AI conversation where one agent asks questions and another provides answers.\n",
      "\n",
      "```python\n",
      "# Simple Q&A workflow\n",
      "from langgraph.graph import StateGraph\n",
      "from typing import TypedDict\n",
      "\n",
      "class ConversationState(TypedDict):\n",
      "    question: str\n",
      "    answer: str\n",
      "    \n",
      "def question_node(state):\n",
      "    return {\"question\": \"What's the capital of France?\"}\n",
      "    \n",
      "def answer_node(state):\n",
      "    return {\"answer\": f\"The answer to '{state['question']}' is Paris.\"}\n",
      "\n",
      "# Build the graph\n",
      "graph = StateGraph(ConversationState)\n",
      "graph.add_node(\"questioner\", question_node)\n",
      "graph.add_node(\"answerer\", answer_node)\n",
      "graph.add_edge(\"questioner\", \"answerer\")\n",
      "graph.set_entry_point(\"questioner\")\n",
      "graph.set_finish_point(\"answerer\")\n",
      "\n",
      "# Run it\n",
      "app = graph.compile()\n",
      "result = app.invoke({})\n",
      "print(f\"Q: {result['question']}\")\n",
      "print(f\"A: {result['answer']}\")\n",
      "```\n",
      "\n",
      "**What just happened?**\n",
      "1. We defined a shared state (ConversationState)\n",
      "2. Created two simple functions (nodes)\n",
      "3. Connected them in sequence\n",
      "4. Ran the workflow\n",
      "\n",
      "Now let's build something more sophisticated...\n",
      "```\n",
      "\n",
      "### 6. **Engagement Improvements**\n",
      "\n",
      "**Add interactive elements throughout**:\n",
      "- \"ðŸš€ **Try This**: Modify the research topic and run the code again\"\n",
      "- \"ðŸ’¡ **Pro Tip**: Use descriptive node names for easier debugging\"\n",
      "- \"âš ï¸ **Common Mistake**: Forgetting to update state can cause data loss\"\n",
      "\n",
      "### 7. **Complete the Best Practices Section**\n",
      "\n",
      "**Current issue**: The best practices are mentioned but not detailed.\n",
      "\n",
      "**Add concrete examples**:\n",
      "```markdown\n",
      "### State Management Best Practices\n",
      "\n",
      "**âŒ Bad State Design:**\n",
      "```python\n",
      "class MessyState(TypedDict):\n",
      "    data: str  # Too vague\n",
      "    stuff: dict  # What kind of stuff?\n",
      "```\n",
      "\n",
      "**âœ… Good State Design:**\n",
      "```python\n",
      "class ClearState(TypedDict):\n",
      "    user_query: str\n",
      "    search_results: List[dict]\n",
      "    generated_response: str\n",
      "    confidence_score: float\n",
      "```\n",
      "\n",
      "**Why this matters**: Clear state schemas prevent bugs and make your code self-documenting.\n",
      "```\n",
      "\n",
      "### 8. **Add Missing Visual Elements**\n",
      "\n",
      "**Suggestion**: Include ASCII diagrams for graph visualization:\n",
      "```markdown\n",
      "### Visualizing Your Workflow\n",
      "\n",
      "```\n",
      "Research Assistant Flow:\n",
      "\n",
      "[Start] â†’ [Researcher] â†’ [Writer] â†’ [Reviewer] â†’ [End]\n",
      "            â†“             â†“           â†“\n",
      "         [Findings]   [Draft]    [Final Content]\n",
      "```\n",
      "\n",
      "This helps readers understand the data flow before diving into code.\n",
      "```\n",
      "\n",
      "### 9. **Strengthen the Conclusion**\n",
      "\n",
      "**Current issue**: The conclusion is generic.\n",
      "\n",
      "**Improved version**:\n",
      "```markdown\n",
      "## What You've Accomplished\n",
      "\n",
      "In this tutorial, you've learned to:\n",
      "- âœ… Set up a complete LangGraph development environment  \n",
      "- âœ… Build a three-agent research assistant from scratch\n",
      "- âœ… Implement state management and data flow\n",
      "- âœ… Handle errors and test your workflows\n",
      "\n",
      "**Your Next Challenge**: Take the research assistant and add a fourth agent that fact-checks the content. This will help you practice conditional routing and more complex state management.\n",
      "\n",
      "**Join the Community**: Share your first LangGraph project in the [LangChain Discord](discord-link) â€“ the community loves seeing what newcomers build!\n",
      "```\n",
      "\n",
      "### 10. **Add Prerequisites Checklist**\n",
      "\n",
      "**Insert after the introduction**:\n",
      "```markdown\n",
      "## Before We Start: Quick Checklist\n",
      "\n",
      "- [ ] Python 3.8+ installed\n",
      "- [ ] Basic familiarity with Python functions and dictionaries\n",
      "- [ ] OpenAI API key (get a free one at platform.openai.com)\n",
      "- [ ] 30 minutes of focused time\n",
      "\n",
      "Don't worry if you're new to AI development â€“ we'll explain everything as we go!\n",
      "```\n",
      "\n",
      "## Summary of Key Improvements Needed\n",
      "\n",
      "1. **Simplify the opening** with concrete examples\n",
      "2. **Add progressive complexity** starting with simpler examples\n",
      "3. **Include more context** around code examples\n",
      "4. **Add troubleshooting guidance** for common issues\n",
      "5. **Enhance visual elements** with diagrams and formatting\n",
      "6. **Strengthen practical sections** with actionable tips\n",
      "7. **Improve conclusion** with specific next steps\n",
      "\n",
      "These changes will significantly improve the tutorial's accessibility, engagement, and practical value for developers new to LangGraph.\n"
     ]
    }
   ],
   "source": [
    "# Display the review\n",
    "print(\"\\nðŸ” REVIEW:\")\n",
    "print(\"-\" * 50)\n",
    "print(result[\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ¨ FINAL CONTENT:\n",
      "--------------------------------------------------\n",
      "# How to Get Started with LangGraph: Building Stateful AI Applications Made Simple\n",
      "\n",
      "Have you ever built a chatbot that couldn't remember what it said two messages ago? Or created an AI workflow that got stuck because it couldn't handle unexpected responses? You're not alone.\n",
      "\n",
      "Most AI applications today follow a simple pattern: input â†’ process â†’ output. But what if your AI needs to collaborate with other AI agents, remember previous decisions, or pause for human approval? That's where **LangGraph** comes in.\n",
      "\n",
      "LangGraph is LangChain's breakthrough library for building AI applications that think, remember, and collaborate like human teams. Instead of simple, linear chains, you can create sophisticated workflows where multiple AI agents work together, maintain shared memory, and adapt to changing conditions in real-time.\n",
      "\n",
      "## Before We Start: Quick Checklist\n",
      "\n",
      "- [ ] Python 3.8+ installed\n",
      "- [ ] Basic familiarity with Python functions and dictionaries\n",
      "- [ ] OpenAI API key (get a free one at platform.openai.com)\n",
      "- [ ] 30 minutes of focused time\n",
      "\n",
      "Don't worry if you're new to AI development â€“ we'll explain everything as we go!\n",
      "\n",
      "## Why LangGraph Matters\n",
      "\n",
      "In today's AI landscape, the most valuable applications aren't just about getting a single response from an LLM. They're about orchestrating complex reasoning processes, enabling multiple specialized agents to work together, and creating workflows that can adapt and improve over time.\n",
      "\n",
      "Traditional AI chains work like assembly lines â€“ rigid and predictable. LangGraph enables you to build AI teams that collaborate, iterate, and make intelligent decisions based on context and previous experiences. Think customer service systems that escalate intelligently, research assistants that verify their own findings, or content creation pipelines with built-in review cycles.\n",
      "\n",
      "## What You'll Learn\n",
      "\n",
      "This comprehensive guide will take you from LangGraph novice to confident practitioner. You'll understand the core concepts that make LangGraph unique, set up a complete development environment, and build multiple applications from simple to sophisticated. We'll also cover essential best practices and troubleshooting guidance.\n",
      "\n",
      "**Prerequisites**: Basic Python programming knowledge and some familiarity with AI concepts. If you've used LangChain before, that's helpful but not required â€“ we'll cover everything you need to know about LangGraph's unique approach.\n",
      "\n",
      "---\n",
      "\n",
      "## Understanding LangGraph Fundamentals\n",
      "\n",
      "Before diving into code, let's understand what makes LangGraph different from traditional AI applications. The key is moving from simple chains to intelligent **graphs** that can handle complex, collaborative workflows.\n",
      "\n",
      "### What Are LangGraph \"Graphs\"?\n",
      "\n",
      "Don't worry â€“ we're not talking about bar charts or pie graphs! In LangGraph, a \"graph\" is like a flowchart that shows how information moves through your AI application.\n",
      "\n",
      "Imagine planning a group project:\n",
      "- **Nodes** = Team members (each with specific roles)\n",
      "- **Edges** = Communication paths between team members  \n",
      "- **State** = The shared project document everyone can read and update\n",
      "\n",
      "This is exactly how LangGraph works, but with AI agents instead of people.\n",
      "\n",
      "### Core Concepts\n",
      "\n",
      "**State Management**: This is LangGraph's superpower. Instead of passing data linearly from one step to the next, LangGraph maintains a shared state that all nodes can read from and write to. Think of it as a shared workspace where AI agents can collaborate by updating common information, remember previous decisions, and build upon each other's work.\n",
      "\n",
      "**Visualizing the Flow**:\n",
      "```\n",
      "Traditional Chain:\n",
      "Input â†’ Agent1 â†’ Agent2 â†’ Output\n",
      "\n",
      "LangGraph Workflow:\n",
      "      [Shared State]\n",
      "         â†— â†™ â†– â†˜\n",
      "    Agent1 âŸ· Agent2\n",
      "         â†˜ â†— â†– â†™\n",
      "      [Shared State]\n",
      "```\n",
      "\n",
      "**Agent vs. Tool Nodes**: LangGraph distinguishes between:\n",
      "- **Agent nodes**: Make decisions and generate responses (like a project manager)\n",
      "- **Tool nodes**: Perform specific actions (like running a database query)\n",
      "\n",
      "This separation creates cleaner architecture and more predictable behavior in complex workflows.\n",
      "\n",
      "### Common Use Cases\n",
      "\n",
      "ðŸ’¡ **Multi-agent conversations**: Different AI personalities collaborating on tasks\n",
      "ðŸ”„ **Complex reasoning workflows**: Research, analysis, and problem-solving that requires iteration\n",
      "ðŸ‘¥ **Human oversight integration**: Approval steps and feedback loops for high-stakes decisions\n",
      "ðŸ”€ **Conditional routing**: Workflows that adapt based on results and context\n",
      "\n",
      "---\n",
      "\n",
      "## Setting Up Your Development Environment\n",
      "\n",
      "Let's get your environment ready for building sophisticated AI applications. You'll need Python 3.8+ installed.\n",
      "\n",
      "### Step 1: Install Required Packages\n",
      "\n",
      "```bash\n",
      "# Core LangGraph installation\n",
      "pip install langgraph\n",
      "\n",
      "# Additional dependencies for this tutorial\n",
      "pip install langchain langchain-openai python-dotenv\n",
      "```\n",
      "\n",
      "**Why these packages?**\n",
      "- `langgraph`: The main library we're learning\n",
      "- `langchain`: Provides LLM integrations\n",
      "- `langchain-openai`: Connects to OpenAI's APIs\n",
      "- `python-dotenv`: Manages environment variables securely\n",
      "\n",
      "### Step 2: Configure API Access\n",
      "\n",
      "Create a `.env` file in your project root to store your API keys securely:\n",
      "\n",
      "```\n",
      "OPENAI_API_KEY=your_openai_key_here\n",
      "ANTHROPIC_API_KEY=your_anthropic_key_here\n",
      "```\n",
      "\n",
      "âš ï¸ **Security Note**: Never commit API keys to version control! The `.env` file should be added to your `.gitignore`.\n",
      "\n",
      "### Step 3: Set Up Project Structure\n",
      "\n",
      "Organize your LangGraph projects with a clear, scalable structure:\n",
      "\n",
      "```\n",
      "my_langgraph_project/\n",
      "â”œâ”€â”€ .env\n",
      "â”œâ”€â”€ .gitignore\n",
      "â”œâ”€â”€ requirements.txt\n",
      "â”œâ”€â”€ main.py\n",
      "â”œâ”€â”€ nodes/\n",
      "â”‚   â”œâ”€â”€ __init__.py\n",
      "â”‚   â”œâ”€â”€ agent_nodes.py\n",
      "â”‚   â””â”€â”€ tool_nodes.py\n",
      "â”œâ”€â”€ graphs/\n",
      "â”‚   â”œâ”€â”€ __init__.py\n",
      "â”‚   â””â”€â”€ workflow.py\n",
      "â””â”€â”€ utils/\n",
      "    â”œâ”€â”€ __init__.py\n",
      "    â””â”€â”€ state.py\n",
      "```\n",
      "\n",
      "### Step 4: Verify Your Installation\n",
      "\n",
      "Test your setup with this simple \"Hello World\" example:\n",
      "\n",
      "```python\n",
      "# test_setup.py\n",
      "import os\n",
      "from dotenv import load_dotenv\n",
      "from langgraph.graph import StateGraph\n",
      "from typing import TypedDict\n",
      "\n",
      "load_dotenv()\n",
      "\n",
      "class State(TypedDict):\n",
      "    message: str\n",
      "\n",
      "def hello_node(state: State) -> State:\n",
      "    return {\"message\": f\"Hello, {state['message']}!\"}\n",
      "\n",
      "# Create and test a minimal graph\n",
      "graph = StateGraph(State)\n",
      "graph.add_node(\"hello\", hello_node)\n",
      "graph.set_entry_point(\"hello\")\n",
      "graph.set_finish_point(\"hello\")\n",
      "\n",
      "app = graph.compile()\n",
      "result = app.invoke({\"message\": \"World\"})\n",
      "print(result)  # Should output: {'message': 'Hello, World!'}\n",
      "```\n",
      "\n",
      "If this runs without errors, your environment is properly configured! ðŸŽ‰\n",
      "\n",
      "### Common Setup Issues & Solutions\n",
      "\n",
      "**\"ModuleNotFoundError: No module named 'langgraph'\"**\n",
      "- Solution: Ensure you're in the correct virtual environment and run `pip install langgraph`\n",
      "\n",
      "**\"AuthenticationError: Invalid API key\"**\n",
      "- Solution: Check your `.env` file format and verify your API key is active\n",
      "\n",
      "**\"Graph execution hangs indefinitely\"**\n",
      "- Solution: Check for infinite loops in your graph structure\n",
      "\n",
      "---\n",
      "\n",
      "## Your First 5-Minute LangGraph App\n",
      "\n",
      "Let's start with something simple â€“ a two-step AI conversation where one agent asks questions and another provides answers.\n",
      "\n",
      "```python\n",
      "# simple_qa.py\n",
      "from langgraph.graph import StateGraph\n",
      "from typing import TypedDict\n",
      "\n",
      "class ConversationState(TypedDict):\n",
      "    question: str\n",
      "    answer: str\n",
      "    \n",
      "def question_node(state: ConversationState) -> ConversationState:\n",
      "    \"\"\"Agent that generates questions\"\"\"\n",
      "    return {\n",
      "        \"question\": \"What's the capital of France?\",\n",
      "        \"answer\": state.get(\"answer\", \"\")\n",
      "    }\n",
      "    \n",
      "def answer_node(state: ConversationState) -> ConversationState:\n",
      "    \"\"\"Agent that provides answers\"\"\"\n",
      "    return {\n",
      "        \"question\": state[\"question\"],\n",
      "        \"answer\": f\"The answer to '{state['question']}' is Paris.\"\n",
      "    }\n",
      "\n",
      "# Build the graph\n",
      "graph = StateGraph(ConversationState)\n",
      "graph.add_node(\"questioner\", question_node)\n",
      "graph.add_node(\"answerer\", answer_node)\n",
      "graph.add_edge(\"questioner\", \"answerer\")\n",
      "graph.set_entry_point(\"questioner\")\n",
      "graph.set_finish_point(\"answerer\")\n",
      "\n",
      "# Run it\n",
      "app = graph.compile()\n",
      "result = app.invoke({\"question\": \"\", \"answer\": \"\"})\n",
      "print(f\"Q: {result['question']}\")\n",
      "print(f\"A: {result['answer']}\")\n",
      "```\n",
      "\n",
      "**What just happened?**\n",
      "1. We defined a shared state (`ConversationState`)\n",
      "2. Created two simple functions (nodes) that read and update the state\n",
      "3. Connected them in sequence with an edge\n",
      "4. Ran the workflow and got our result\n",
      "\n",
      "ðŸš€ **Try This**: Modify the question and run the code again to see how the state flows between nodes.\n",
      "\n",
      "Now let's build something more sophisticated...\n",
      "\n",
      "---\n",
      "\n",
      "## Building Your First Real LangGraph Application\n",
      "\n",
      "Let's create a research assistant that demonstrates LangGraph's true power. Our assistant will have three specialized agents working together: a researcher, a writer, and a reviewer.\n",
      "\n",
      "### Step 1: Design the State Schema\n",
      "\n",
      "First, let's define what information our agents will share:\n",
      "\n",
      "```python\n",
      "# research_assistant.py\n",
      "import os\n",
      "from typing import TypedDict, List\n",
      "from dotenv import load_dotenv\n",
      "from langgraph.graph import StateGraph\n",
      "from langchain_openai import ChatOpenAI\n",
      "\n",
      "load_dotenv()\n",
      "\n",
      "class ResearchState(TypedDict):\n",
      "    topic: str                    # What we're researching\n",
      "    research_findings: List[str]  # Key discoveries\n",
      "    draft_content: str           # Initial write-up\n",
      "    final_content: str           # Polished result\n",
      "    review_feedback: str         # Quality assessment\n",
      "    iteration_count: int         # How many rounds we've done\n",
      "    status: str                  # Current workflow stage\n",
      "```\n",
      "\n",
      "ðŸ’¡ **Pro Tip**: Clear state schemas prevent bugs and make your code self-documenting.\n",
      "\n",
      "### Step 2: Create Specialized Agent Nodes\n",
      "\n",
      "Now let's implement each AI agent with distinct responsibilities:\n",
      "\n",
      "```python\n",
      "# Initialize our LLM\n",
      "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
      "\n",
      "def researcher_node(state: ResearchState) -> ResearchState:\n",
      "    \"\"\"Gather information about the research topic\"\"\"\n",
      "    prompt = f\"\"\"Research the topic: {state['topic']}\n",
      "    \n",
      "    Provide 3-4 key findings as separate points. Focus on:\n",
      "    - Current trends and developments\n",
      "    - Important statistics or data\n",
      "    - Key challenges or opportunities\n",
      "    - Expert opinions or notable quotes\n",
      "    \n",
      "    Format each finding as a clear, concise bullet point.\"\"\"\n",
      "    \n",
      "    try:\n",
      "        response = llm.invoke(prompt)\n",
      "        # Split response into individual findings\n",
      "        findings = [f.strip() for f in response.content.split('\\n') if f.strip() and f.strip().startswith('â€¢')]\n",
      "        \n",
      "        return {\n",
      "            **state,\n",
      "            \"research_findings\": findings,\n",
      "            \"status\": \"research_complete\"\n",
      "        }\n",
      "    except Exception as e:\n",
      "        return {\n",
      "            **state,\n",
      "            \"status\": f\"research_error: {str(e)}\"\n",
      "        }\n",
      "\n",
      "def writer_node(state: ResearchState) -> ResearchState:\n",
      "    \"\"\"Transform research findings into coherent content\"\"\"\n",
      "    if state['status'] != \"research_complete\":\n",
      "        return {**state, \"status\": \"writer_skipped\"}\n",
      "    \n",
      "    findings_text = '\\n'.join(state['research_findings'])\n",
      "    prompt = f\"\"\"Based on these research findings about {state['topic']}, write a comprehensive, engaging summary:\n",
      "\n",
      "    {findings_text}\n",
      "    \n",
      "    Requirements:\n",
      "    - Write in a clear, professional tone\n",
      "    - Structure with introduction, main points, and conclusion\n",
      "    - Make it informative but accessible\n",
      "    - Aim for 200-300 words\n",
      "    \"\"\"\n",
      "    \n",
      "    try:\n",
      "        response = llm.invoke(prompt)\n",
      "        return {\n",
      "            **state,\n",
      "            \"draft_content\": response.content,\n",
      "            \"status\": \"draft_complete\"\n",
      "        }\n",
      "    except Exception as e:\n",
      "        return {\n",
      "            **state,\n",
      "            \"status\": f\"writer_error: {str(e)}\"\n",
      "        }\n",
      "\n",
      "def reviewer_node(state: ResearchState) -> ResearchState:\n",
      "    \"\"\"Review content and provide quality assessment\"\"\"\n",
      "    if state['status'] != \"draft_complete\":\n",
      "        return {**state, \"status\": \"reviewer_skipped\"}\n",
      "    \n",
      "    prompt = f\"\"\"Review this content about {state['topic']} and provide feedback:\n",
      "\n",
      "    {state['draft_content']}\n",
      "    \n",
      "    Evaluate:\n",
      "    - Clarity and readability\n",
      "    - Accuracy based on the research findings\n",
      "    - Completeness of coverage\n",
      "    - Overall quality\n",
      "    \n",
      "    Provide specific feedback and a quality score (1-10).\"\"\"\n",
      "    \n",
      "    try:\n",
      "        response = llm.invoke(prompt)\n",
      "        return {\n",
      "            **state,\n",
      "            \"review_feedback\": response.content,\n",
      "            \"final_content\": state['draft_content'],  # In a real app, you might revise based on feedback\n",
      "            \"status\": \"review_complete\",\n",
      "            \"iteration_count\": state.get('iteration_count', 0) + 1\n",
      "        }\n",
      "    except Exception as e:\n",
      "        return {\n",
      "            **state,\n",
      "            \"status\": f\"reviewer_error: {str(e)}\"\n",
      "        }\n",
      "```\n",
      "\n",
      "### Step 3: Assemble the Workflow\n",
      "\n",
      "Now let's connect our agents into a collaborative workflow:\n",
      "\n",
      "```python\n",
      "def create_research_graph():\n",
      "    \"\"\"Build and return a compiled research assistant graph\"\"\"\n",
      "    graph = StateGraph(ResearchState)\n",
      "    \n",
      "    # Add our specialized agents\n",
      "    graph.add_node(\"researcher\", researcher_node)\n",
      "    graph.add_node(\"writer\", writer_node)\n",
      "    graph.add_node(\"reviewer\", reviewer_node)\n",
      "    \n",
      "    # Define the workflow sequence\n",
      "    graph.set_entry_point(\"researcher\")\n",
      "    graph.add_edge(\"researcher\", \"writer\")\n",
      "    graph.add_edge(\"writer\", \"reviewer\")\n",
      "    graph.set_finish_point(\"reviewer\")\n",
      "    \n",
      "    return graph.compile()\n",
      "\n",
      "# Create and test the application\n",
      "research_app = create_research_graph()\n",
      "\n",
      "# Set up initial state\n",
      "initial_state = {\n",
      "    \"topic\": \"The impact of artificial intelligence on education\",\n",
      "    \"research_findings\": [],\n",
      "    \"draft_content\": \"\",\n",
      "    \"final_content\": \"\",\n",
      "    \"review_feedback\": \"\",\n",
      "    \"iteration_count\": 0,\n",
      "    \"status\": \"initialized\"\n",
      "}\n",
      "\n",
      "print(\"ðŸ¤– Research Assistant Starting...\\n\")\n",
      "print(f\"Topic: {initial_state['topic']}\")\n",
      "print(\"-\" * 50)\n",
      "\n",
      "# Run the research workflow\n",
      "result = research_app.invoke(initial_state)\n",
      "\n",
      "# Display results\n",
      "print(\"âœ… Research Complete!\")\n",
      "print(f\"Status: {result['status']}\")\n",
      "print(f\"Iterations: {result['iteration_count']}\")\n",
      "print(\"\\nðŸ“‹ Final Content:\")\n",
      "print(result['final_content'])\n",
      "print(f\"\\nðŸ“ Review Feedback:\")\n",
      "print(result['review_feedback'])\n",
      "```\n",
      "\n",
      "### Step 4: Understanding the Data Flow\n",
      "\n",
      "Here's what happens when you run this workflow:\n",
      "\n",
      "```\n",
      "Research Assistant Flow:\n",
      "\n",
      "[Start] â†’ [Researcher] â†’ [Writer] â†’ [Reviewer] â†’ [End]\n",
      "            â†“             â†“           â†“\n",
      "         [Findings]   [Draft]    [Final + Review]\n",
      "```\n",
      "\n",
      "1. **Researcher** receives the topic and populates `research_findings`\n",
      "2. **Writer** reads the findings and creates `draft_content`\n",
      "3. **Reviewer** evaluates the draft and provides `review_feedback`\n",
      "4. Each agent updates the `status` to coordinate the workflow\n",
      "\n",
      "ðŸš€ **Try This**: Change the research topic to something you're interested in and watch how each agent contributes to the final result.\n",
      "\n",
      "### Testing and Debugging Tips\n",
      "\n",
      "**Monitor State Changes**: Add debug prints to see how state evolves:\n",
      "```python\n",
      "def debug_node(state):\n",
      "    print(f\"Current state: {state}\")\n",
      "    return state\n",
      "\n",
      "graph.add_node(\"debug\", debug_node)\n",
      "```\n",
      "\n",
      "**Handle Errors Gracefully**: Each node includes try-catch blocks to prevent workflow crashes.\n",
      "\n",
      "**Validate State**: Check that required fields exist before processing:\n",
      "```python\n",
      "if not state.get('research_findings'):\n",
      "    return {**state, \"status\": \"no_research_data\"}\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## Advanced Patterns and Best Practices\n",
      "\n",
      "As you build more sophisticated LangGraph applications, these patterns will help you create robust, maintainable code.\n",
      "\n",
      "### State Management Best Practices\n",
      "\n",
      "**âŒ Bad State Design:**\n",
      "```python\n",
      "class MessyState(TypedDict):\n",
      "    data: str        # Too vague\n",
      "    stuff: dict      # What kind of stuff?\n",
      "    info: List       # What kind of info?\n",
      "```\n",
      "\n",
      "**âœ… Good State Design:**\n",
      "```python\n",
      "class ClearState(TypedDict):\n",
      "    user_query: str\n",
      "    search_results: List[dict]\n",
      "    generated_response: str\n",
      "    confidence_score: float\n",
      "    processing_errors: List[str]\n",
      "```\n",
      "\n",
      "### Error Handling Patterns\n",
      "\n",
      "**Implement Circuit Breakers**: Prevent infinite loops and cascading failures:\n",
      "```python\n",
      "def safe_node(state):\n",
      "    if state.get('error_count', 0) > 3:\n",
      "        return {**state, \"status\": \"max_errors_reached\"}\n",
      "    \n",
      "    try:\n",
      "        # Your node logic here\n",
      "        return process_normally(state)\n",
      "    except Exception as e:\n",
      "        return {\n",
      "            **state, \n",
      "            \"error_count\": state.get('error_count', 0) + 1,\n",
      "            \"last_error\": str(e)\n",
      "        }\n",
      "```\n",
      "\n",
      "### Performance Optimization\n",
      "\n",
      "**Cache Expensive Operations**:\n",
      "```python\n",
      "from functools import lru_cache\n",
      "\n",
      "@lru_cache(maxsize=100)\n",
      "def expensive_research_call(topic):\n",
      "    # Expensive API call or computation\n",
      "    return llm.invoke(f\"Research: {topic}\")\n",
      "```\n",
      "\n",
      "**Implement Timeouts**:\n",
      "```python\n",
      "import signal\n",
      "\n",
      "def timeout_handler(signum, frame):\n",
      "    raise TimeoutError(\"Operation timed out\")\n",
      "\n",
      "def node_with_timeout(state):\n",
      "    signal.signal(signal.SIGALRM, timeout_handler)\n",
      "    signal.alarm(30)  # 30 second timeout\n",
      "    \n",
      "    try:\n",
      "        result = slow_operation(state)\n",
      "        signal.alarm(0)  # Cancel timeout\n",
      "        return result\n",
      "    except TimeoutError:\n",
      "        return {**state, \"status\": \"timeout_error\"}\n",
      "```\n",
      "\n",
      "### Advanced Workflow Patterns\n",
      "\n",
      "**Conditional Routing**: Make decisions based on state:\n",
      "```python\n",
      "def router_node(state):\n",
      "    if state['confidence_score'] > 0.8:\n",
      "        return \"high_confidence_path\"\n",
      "    else:\n",
      "        return \"needs_review_path\"\n",
      "\n",
      "graph.add_conditional_edges(\"processor\", router_node, {\n",
      "    \"high_confidence_path\": \"finalizer\",\n",
      "    \"needs_review_path\": \"reviewer\"\n",
      "})\n",
      "```\n",
      "\n",
      "**Human-in-the-Loop**: Pause for human input:\n",
      "```python\n",
      "def human_review_node(state):\n",
      "    print(f\"Content for review: {state['draft_content']}\")\n",
      "    feedback = input(\"Your feedback (or 'approve' to continue): \")\n",
      "    \n",
      "    return {\n",
      "        **state,\n",
      "        \"human_feedback\": feedback,\n",
      "        \"status\": \"human_reviewed\"\n",
      "    }\n",
      "```\n",
      "\n",
      "**Iterative Improvement**: Loop until quality threshold is met:\n",
      "```python\n",
      "def quality_check(state):\n",
      "    score = extract_score(state['review_feedback'])\n",
      "    if score >= 8 or state['iteration_count'] >= 3:\n",
      "        return \"finish\"\n",
      "    else:\n",
      "        return \"revise\"\n",
      "\n",
      "graph.add_conditional_edges(\"reviewer\", quality_check, {\n",
      "    \"finish\": END,\n",
      "    \"revise\": \"writer\"\n",
      "})\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## Troubleshooting Common Issues\n",
      "\n",
      "### Graph Structure Problems\n",
      "\n",
      "**Issue: Infinite Loops**\n",
      "```python\n",
      "# âŒ This creates an infinite loop:\n",
      "graph.add_edge(\"node_a\", \"node_b\")\n",
      "graph.add_edge(\"node_b\", \"node_a\")\n",
      "```\n",
      "\n",
      "**Solution: Add Exit Conditions**\n",
      "```python\n",
      "def loop_controller(state):\n",
      "    if state['iteration_count'] > 5:\n",
      "        return \"end\"\n",
      "    else:\n",
      "        return \"continue\"\n",
      "\n",
      "graph.add_conditional_edges(\"processor\", loop_controller)\n",
      "```\n",
      "\n",
      "**Issue: Orphaned Nodes**\n",
      "- Check that every node is reachable from the entry point\n",
      "- Verify all paths lead to a finish point\n",
      "\n",
      "**Issue: State Corruption**\n",
      "- Always return complete state dictionaries\n",
      "- Use `{**state, \"new_field\": value}` pattern to preserve existing state\n",
      "\n",
      "### Performance Issues\n",
      "\n",
      "**Slow Execution**:\n",
      "- Profile your LLM calls â€“ they're usually the bottleneck\n",
      "- Consider parallel execution for independent nodes\n",
      "- Implement caching for repeated operations\n",
      "\n",
      "**High Token Usage**:\n",
      "- Monitor and limit prompt lengths\n",
      "- Use cheaper models for simple tasks\n",
      "- Implement token usage tracking\n",
      "\n",
      "**Memory Problems**:\n",
      "- Clear large state fields when no longer needed\n",
      "- Use generators for processing large datasets\n",
      "- Implement state persistence for long-running workflows\n",
      "\n",
      "---\n",
      "\n",
      "## Next Steps and Advanced Features\n",
      "\n",
      "### Features to Explore\n",
      "\n",
      "**ðŸ”„ Streaming and Real-time Updates**: Provide progress updates during long-running workflows\n",
      "```python\n",
      "for chunk in app.stream(initial_state):\n",
      "    print(f\"Progress: {chunk}\")\n",
      "```\n",
      "\n",
      "**ðŸ’¾ Persistence and Checkpointing**: Save state to resume workflows after interruptions\n",
      "```python\n",
      "from langgraph.checkpoint.sqlite import SqliteSaver\n",
      "\n",
      "checkpointer = SqliteSaver.from_conn_string(\"./workflow_state.db\")\n",
      "app = graph.compile(checkpointer=checkpointer)\n",
      "```\n",
      "\n",
      "**ðŸ”§ Custom Tool Integration**: Connect to external APIs and services\n",
      "```python\n",
      "from langchain_community.tools import ShellTool, SQLDatabaseQueryTool\n",
      "\n",
      "def tool_node(state):\n",
      "    shell = ShellTool()\n",
      "    result = shell.run(\"ls -la\")\n",
      "    return {**state, \"file_list\": result}\n",
      "```\n",
      "\n",
      "**ðŸ‘¥ Multi-User Workflows**: Handle multiple users in the same workflow\n",
      "```python\n",
      "class MultiUserState(TypedDict):\n",
      "    user_id: str\n",
      "    user_inputs: dict\n",
      "    shared_workspace: dict\n",
      "```\n",
      "\n",
      "### Building Real-World Applications\n",
      "\n",
      "**Customer Service Bot**:\n",
      "- Intent classification â†’ Specialist routing â†’ Response generation â†’ Quality check\n",
      "\n",
      "**Content Creation Pipeline**:\n",
      "- Research â†’ Writing â†’ Editing â†’ Fact-checking â†’ Publishing\n",
      "\n",
      "**Data Analysis Workflow**:\n",
      "- Data ingestion â†’ Cleaning â†’ Analysis â†’ Visualization â†’ Report generation\n",
      "\n",
      "### Integration Opportunities\n",
      "\n",
      "**Vector Databases**: Combine with Pinecone, Weaviate, or Chroma for semantic search\n",
      "**Document Processing**: Integrate with LangChain's document loaders and text splitters\n",
      "**API Integrations**: Connect to business systems, databases, and external services\n",
      "**Monitoring**: Add logging, metrics, and observability to production workflows\n",
      "\n",
      "---\n",
      "\n",
      "## What You've Accomplished\n",
      "\n",
      "Congratulations! In this tutorial, you've learned to:\n",
      "- âœ… Set up a complete LangGraph development environment  \n",
      "- âœ… Understand core concepts: graphs, nodes, edges, and state management\n",
      "- âœ… Build a three-agent research assistant from scratch\n",
      "- âœ… Implement error handling and workflow control\n",
      "- âœ… Apply best practices for maintainable code\n",
      "- âœ… Troubleshoot common issues and optimize performance\n",
      "\n",
      "**Your Next Challenge**: Take the research assistant and add a fourth agent that fact-checks the content against reliable sources. This will help you practice conditional routing, external tool integration, and more complex state management.\n",
      "\n",
      "**Real-World Project Ideas**:\n",
      "1. **Smart Email Classifier**: Route emails through different processing pipelines based on content\n",
      "2. **Content Quality Pipeline**: Multi-stage content creation with automated and human reviews\n",
      "3. **Research Synthesis Bot**: Gather information from multiple sources and create comprehensive reports\n",
      "\n",
      "**Join the Community**: Share your first LangGraph project in the [LangChain Discord](https://discord.gg/langchain) â€“ the community loves seeing what newcomers build!\n",
      "\n",
      "Ready to dive deeper? Check out the [official LangGraph documentation](https://langchain-ai.github.io/langgraph/) and explore the growing ecosystem of LangGraph applications. Your next breakthrough is just one graph away! ðŸš€\n",
      "\n",
      "---\n",
      "\n",
      "## Additional Resources\n",
      "\n",
      "**ðŸ“š Documentation & Guides**:\n",
      "- [LangGraph Official Docs](https://langchain-ai.github.io/langgraph/)\n",
      "- [LangChain Community Hub](https://github.com/langchain-ai/langchain)\n",
      "- [Example Projects Repository](https://github.com/langchain-ai/langgraph/tree/main/examples)\n",
      "\n",
      "**ðŸ¤ Community & Support**:\n",
      "- [LangChain Discord Server](https://discord.gg/langchain)\n",
      "- [GitHub Discussions](https://github.com/langchain-ai/langgraph/discussions)\n",
      "- [Twitter Community](https://twitter.com/langchainai)\n",
      "\n",
      "**ðŸŽ“ Learning Path**:\n",
      "1. Master the basics with this tutorial\n",
      "2. Build 2-3 practice projects\n",
      "3. Explore advanced patterns (streaming, persistence, tools)\n",
      "4. Contribute to the community with your own examples\n",
      "\n",
      "The future of AI applications is collaborative, stateful, and intelligent. With LangGraph, you're equipped to build it! ðŸŒŸ\n"
     ]
    }
   ],
   "source": [
    "# Display the final content\n",
    "print(\"\\nâœ¨ FINAL CONTENT:\")\n",
    "print(\"-\" * 50)\n",
    "print(result[\"final_content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding State Updates\n",
    "\n",
    "Notice how each node receives the full state and returns partial updates. LangGraph merges these updates automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Build Your Own Pipeline\n",
    "\n",
    "Create a research pipeline that:\n",
    "1. Takes a research question\n",
    "2. Generates key research areas to explore\n",
    "3. Creates a research plan\n",
    "4. Summarizes potential findings\n",
    "\n",
    "Use the pattern above as a template!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "\n",
    "class ResearchState(TypedDict):\n",
    "    question: str\n",
    "    research_areas: str\n",
    "    research_plan: str\n",
    "    summary: str\n",
    "\n",
    "# TODO: Define your nodes\n",
    "# TODO: Build your graph\n",
    "# TODO: Run it with a research question\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. âœ… How to create graphs with multiple nodes\n",
    "2. âœ… Managing complex state with multiple fields\n",
    "3. âœ… Building linear workflows where data flows through stages\n",
    "4. âœ… How nodes update state through partial returns\n",
    "5. âœ… Creating practical multi-step pipelines\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **Topic 3: Conditional Edges** to learn how to add decision-making to your graphs!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
