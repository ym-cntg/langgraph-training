{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {},
      "source": [
        "# Topic 6: Subgraphs\n",
        "\n",
        "Learn how to build modular, reusable graph components using subgraphs. Create complex applications by composing smaller graphs together.\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "- Understand subgraphs and modularity\n",
        "- Create reusable graph components\n",
        "- Compose subgraphs into larger workflows\n",
        "- Manage state between parent and child graphs\n",
        "- Build maintainable, scalable applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import getpass\n",
        "from typing import TypedDict, Literal, Annotated\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "from langchain_core.messages import HumanMessage\n",
        "import operator\n",
        "\n",
        "if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
        "\n",
        "model = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\")\n",
        "print(\"‚úì Setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-2",
      "metadata": {},
      "source": [
        "## What are Subgraphs?\n",
        "\n",
        "Subgraphs allow you to:\n",
        "- **Encapsulate logic**: Package related functionality into reusable components\n",
        "- **Improve maintainability**: Separate concerns and organize complex workflows\n",
        "- **Enable reuse**: Use the same subgraph in multiple places\n",
        "- **Simplify testing**: Test subgraphs independently\n",
        "\n",
        "Think of subgraphs as functions that are themselves complete graphs. You can call them from parent graphs just like nodes!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {},
      "source": [
        "## Example 1: Reusable Validation Subgraph\n",
        "\n",
        "Let's create a validation subgraph that can be reused across different workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for the validation subgraph\n",
        "class ValidationState(TypedDict):\n",
        "    data: str\n",
        "    validation_result: str\n",
        "    is_valid: bool\n",
        "    error_messages: list[str]\n",
        "\n",
        "print(\"‚úì ValidationState defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create validation nodes\n",
        "def check_length(state: ValidationState) -> ValidationState:\n",
        "    \"\"\"Check if data meets length requirements.\"\"\"\n",
        "    print(\"   üìè Checking length...\")\n",
        "    \n",
        "    errors = state.get(\"error_messages\", [])\n",
        "    data = state[\"data\"]\n",
        "    \n",
        "    if len(data) < 10:\n",
        "        errors.append(\"Data too short (minimum 10 characters)\")\n",
        "    elif len(data) > 500:\n",
        "        errors.append(\"Data too long (maximum 500 characters)\")\n",
        "    \n",
        "    return {\"error_messages\": errors}\n",
        "\n",
        "def check_format(state: ValidationState) -> ValidationState:\n",
        "    \"\"\"Check if data has valid format.\"\"\"\n",
        "    print(\"   üìã Checking format...\")\n",
        "    \n",
        "    errors = state.get(\"error_messages\", [])\n",
        "    data = state[\"data\"]\n",
        "    \n",
        "    # Use LLM to validate format and content quality\n",
        "    prompt = f\"\"\"Analyze this text and identify any formatting or content quality issues:\n",
        "\n",
        "{data}\n",
        "\n",
        "If there are issues, list them briefly (one per line).\n",
        "If the text is good quality and well-formatted, respond with: \"No issues found\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    if \"no issues\" not in response.content.lower():\n",
        "        errors.append(f\"Format issues: {response.content[:100]}\")\n",
        "    \n",
        "    return {\"error_messages\": errors}\n",
        "\n",
        "def finalize_validation(state: ValidationState) -> ValidationState:\n",
        "    \"\"\"Finalize validation results.\"\"\"\n",
        "    print(\"   ‚úÖ Finalizing validation...\")\n",
        "    \n",
        "    errors = state.get(\"error_messages\", [])\n",
        "    is_valid = len(errors) == 0\n",
        "    \n",
        "    if is_valid:\n",
        "        result = \"‚úì Validation passed\"\n",
        "    else:\n",
        "        result = f\"‚úó Validation failed: {len(errors)} issue(s) found\"\n",
        "    \n",
        "    return {\n",
        "        \"is_valid\": is_valid,\n",
        "        \"validation_result\": result\n",
        "    }\n",
        "\n",
        "print(\"‚úì Validation nodes created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the validation subgraph\n",
        "validation_builder = StateGraph(ValidationState)\n",
        "\n",
        "# Add nodes\n",
        "validation_builder.add_node(\"check_length\", check_length)\n",
        "validation_builder.add_node(\"check_format\", check_format)\n",
        "validation_builder.add_node(\"finalize\", finalize_validation)\n",
        "\n",
        "# Add edges\n",
        "validation_builder.add_edge(START, \"check_length\")\n",
        "validation_builder.add_edge(\"check_length\", \"check_format\")\n",
        "validation_builder.add_edge(\"check_format\", \"finalize\")\n",
        "validation_builder.add_edge(\"finalize\", END)\n",
        "\n",
        "# Compile the subgraph\n",
        "validation_subgraph = validation_builder.compile()\n",
        "\n",
        "print(\"‚úì Validation subgraph compiled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {},
      "source": [
        "## Test the Validation Subgraph\n",
        "\n",
        "Let's test our reusable validation component:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with valid data\n",
        "print(\"\\nTest 1: Valid data\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = validation_subgraph.invoke({\n",
        "    \"data\": \"This is a well-formatted piece of text that meets all requirements and contains meaningful content.\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"is_valid\": False,\n",
        "    \"error_messages\": []\n",
        "})\n",
        "\n",
        "print(f\"\\nResult: {result['validation_result']}\")\n",
        "print(f\"Valid: {result['is_valid']}\")\n",
        "if result['error_messages']:\n",
        "    print(f\"Errors: {result['error_messages']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with invalid data\n",
        "print(\"\\nTest 2: Invalid data (too short)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = validation_subgraph.invoke({\n",
        "    \"data\": \"Short\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"is_valid\": False,\n",
        "    \"error_messages\": []\n",
        "})\n",
        "\n",
        "print(f\"\\nResult: {result['validation_result']}\")\n",
        "print(f\"Valid: {result['is_valid']}\")\n",
        "if result['error_messages']:\n",
        "    print(f\"Errors:\")\n",
        "    for error in result['error_messages']:\n",
        "        print(f\"  - {error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-10",
      "metadata": {},
      "source": [
        "## Example 2: Using Subgraphs in a Parent Workflow\n",
        "\n",
        "Now let's use our validation subgraph as part of a larger content processing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-11",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define state for the parent workflow\n",
        "class ContentProcessingState(TypedDict):\n",
        "    raw_content: str\n",
        "    data: str  # Used by validation subgraph\n",
        "    validation_result: str  # Used by validation subgraph\n",
        "    is_valid: bool  # Used by validation subgraph\n",
        "    error_messages: list[str]  # Used by validation subgraph\n",
        "    processed_content: str\n",
        "    final_output: str\n",
        "    processing_status: str\n",
        "\n",
        "print(\"‚úì ContentProcessingState defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create parent workflow nodes\n",
        "def prepare_content(state: ContentProcessingState) -> ContentProcessingState:\n",
        "    \"\"\"Prepare raw content for validation.\"\"\"\n",
        "    print(\"\\nüì• Preparing content...\")\n",
        "    \n",
        "    # Copy raw content to the field expected by validation subgraph\n",
        "    return {\n",
        "        \"data\": state[\"raw_content\"],\n",
        "        \"error_messages\": []\n",
        "    }\n",
        "\n",
        "def process_valid_content(state: ContentProcessingState) -> ContentProcessingState:\n",
        "    \"\"\"Process content that passed validation.\"\"\"\n",
        "    print(\"\\n‚öôÔ∏è  Processing valid content...\")\n",
        "    \n",
        "    prompt = f\"\"\"Enhance and improve this content while maintaining its core message:\n",
        "\n",
        "{state['data']}\n",
        "\n",
        "Make it more engaging and well-structured.\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    return {\n",
        "        \"processed_content\": response.content,\n",
        "        \"final_output\": response.content,\n",
        "        \"processing_status\": \"success\"\n",
        "    }\n",
        "\n",
        "def handle_invalid_content(state: ContentProcessingState) -> ContentProcessingState:\n",
        "    \"\"\"Handle content that failed validation.\"\"\"\n",
        "    print(\"\\n‚ùå Handling invalid content...\")\n",
        "    \n",
        "    errors = \"\\n\".join([f\"  - {err}\" for err in state.get(\"error_messages\", [])])\n",
        "    \n",
        "    return {\n",
        "        \"final_output\": f\"Content validation failed. Issues found:\\n{errors}\",\n",
        "        \"processing_status\": \"validation_failed\"\n",
        "    }\n",
        "\n",
        "def route_after_validation(state: ContentProcessingState) -> Literal[\"process\", \"reject\"]:\n",
        "    \"\"\"Route based on validation results.\"\"\"\n",
        "    if state.get(\"is_valid\", False):\n",
        "        print(\"‚úì Routing to processing...\")\n",
        "        return \"process\"\n",
        "    else:\n",
        "        print(\"‚úó Routing to rejection...\")\n",
        "        return \"reject\"\n",
        "\n",
        "print(\"‚úì Parent workflow nodes created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build the parent workflow that uses the validation subgraph\n",
        "workflow_builder = StateGraph(ContentProcessingState)\n",
        "\n",
        "# Add nodes - including the validation subgraph as a node!\n",
        "workflow_builder.add_node(\"prepare\", prepare_content)\n",
        "workflow_builder.add_node(\"validate\", validation_subgraph)  # Subgraph as a node!\n",
        "workflow_builder.add_node(\"process\", process_valid_content)\n",
        "workflow_builder.add_node(\"reject\", handle_invalid_content)\n",
        "\n",
        "# Add edges\n",
        "workflow_builder.add_edge(START, \"prepare\")\n",
        "workflow_builder.add_edge(\"prepare\", \"validate\")\n",
        "\n",
        "# Conditional routing after validation\n",
        "workflow_builder.add_conditional_edges(\n",
        "    \"validate\",\n",
        "    route_after_validation,\n",
        "    {\n",
        "        \"process\": \"process\",\n",
        "        \"reject\": \"reject\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_builder.add_edge(\"process\", END)\n",
        "workflow_builder.add_edge(\"reject\", END)\n",
        "\n",
        "# Compile the parent workflow\n",
        "content_workflow = workflow_builder.compile()\n",
        "\n",
        "print(\"‚úì Content processing workflow compiled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-14",
      "metadata": {},
      "source": [
        "## Visualize the Complete Workflow\n",
        "\n",
        "Notice how the validation subgraph appears as a single node in the parent graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-15",
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "try:\n",
        "    display(Image(content_workflow.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    print(\"Graph structure:\")\n",
        "    print(\"START -> prepare -> validate (subgraph) -> [process|reject] -> END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-16",
      "metadata": {},
      "source": [
        "## Test the Complete Workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-17",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with valid content\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Test 1: Valid Content\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = content_workflow.invoke({\n",
        "    \"raw_content\": \"LangGraph is a powerful framework for building stateful LLM applications with complex workflows.\",\n",
        "    \"data\": \"\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"is_valid\": False,\n",
        "    \"error_messages\": [],\n",
        "    \"processed_content\": \"\",\n",
        "    \"final_output\": \"\",\n",
        "    \"processing_status\": \"\"\n",
        "})\n",
        "\n",
        "print(f\"\\nüìä Status: {result['processing_status']}\")\n",
        "print(f\"\\nüìÑ Final Output:\\n{result['final_output']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with invalid content\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Test 2: Invalid Content\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "result = content_workflow.invoke({\n",
        "    \"raw_content\": \"Short\",\n",
        "    \"data\": \"\",\n",
        "    \"validation_result\": \"\",\n",
        "    \"is_valid\": False,\n",
        "    \"error_messages\": [],\n",
        "    \"processed_content\": \"\",\n",
        "    \"final_output\": \"\",\n",
        "    \"processing_status\": \"\"\n",
        "})\n",
        "\n",
        "print(f\"\\nüìä Status: {result['processing_status']}\")\n",
        "print(f\"\\nüìÑ Final Output:\\n{result['final_output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-19",
      "metadata": {},
      "source": [
        "## Example 3: Data Processing Pipeline with Multiple Subgraphs\n",
        "\n",
        "Let's build a more complex example with multiple reusable subgraphs for data processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-20",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subgraph 1: Data Extraction\n",
        "class ExtractionState(TypedDict):\n",
        "    raw_data: str\n",
        "    extracted_entities: list[str]\n",
        "    extracted_keywords: list[str]\n",
        "\n",
        "def extract_entities(state: ExtractionState) -> ExtractionState:\n",
        "    \"\"\"Extract named entities from text.\"\"\"\n",
        "    print(\"   üîç Extracting entities...\")\n",
        "    \n",
        "    prompt = f\"\"\"Extract all named entities (people, organizations, locations) from this text:\n",
        "\n",
        "{state['raw_data']}\n",
        "\n",
        "List them separated by commas.\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    entities = [e.strip() for e in response.content.split(',')]\n",
        "    \n",
        "    return {\"extracted_entities\": entities}\n",
        "\n",
        "def extract_keywords(state: ExtractionState) -> ExtractionState:\n",
        "    \"\"\"Extract key themes and topics.\"\"\"\n",
        "    print(\"   üè∑Ô∏è  Extracting keywords...\")\n",
        "    \n",
        "    prompt = f\"\"\"Extract 5 key themes or topics from this text:\n",
        "\n",
        "{state['raw_data']}\n",
        "\n",
        "List them separated by commas.\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    keywords = [k.strip() for k in response.content.split(',')[:5]]\n",
        "    \n",
        "    return {\"extracted_keywords\": keywords}\n",
        "\n",
        "# Build extraction subgraph\n",
        "extraction_builder = StateGraph(ExtractionState)\n",
        "extraction_builder.add_node(\"extract_entities\", extract_entities)\n",
        "extraction_builder.add_node(\"extract_keywords\", extract_keywords)\n",
        "extraction_builder.add_edge(START, \"extract_entities\")\n",
        "extraction_builder.add_edge(\"extract_entities\", \"extract_keywords\")\n",
        "extraction_builder.add_edge(\"extract_keywords\", END)\n",
        "extraction_subgraph = extraction_builder.compile()\n",
        "\n",
        "print(\"‚úì Extraction subgraph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Subgraph 2: Data Enrichment\n",
        "class EnrichmentState(TypedDict):\n",
        "    extracted_entities: list[str]\n",
        "    extracted_keywords: list[str]\n",
        "    enriched_data: str\n",
        "    summary: str\n",
        "\n",
        "def enrich_data(state: EnrichmentState) -> EnrichmentState:\n",
        "    \"\"\"Enrich extracted data with additional context.\"\"\"\n",
        "    print(\"   üíé Enriching data...\")\n",
        "    \n",
        "    entities_str = \", \".join(state.get(\"extracted_entities\", []))\n",
        "    keywords_str = \", \".join(state.get(\"extracted_keywords\", []))\n",
        "    \n",
        "    prompt = f\"\"\"Provide brief context about these entities and topics:\n",
        "\n",
        "Entities: {entities_str}\n",
        "Topics: {keywords_str}\n",
        "\n",
        "Be concise and informative.\"\"\"\n",
        "    \n",
        "    response = model.invoke([HumanMessage(content=prompt)])\n",
        "    \n",
        "    return {\"enriched_data\": response.content}\n",
        "\n",
        "def create_summary(state: EnrichmentState) -> EnrichmentState:\n",
        "    \"\"\"Create a summary of the enriched data.\"\"\"\n",
        "    print(\"   üìù Creating summary...\")\n",
        "    \n",
        "    summary = f\"\"\"Data Analysis Summary:\n",
        "- Entities found: {len(state.get('extracted_entities', []))}\n",
        "- Key topics: {len(state.get('extracted_keywords', []))}\n",
        "\n",
        "Enrichment:\n",
        "{state.get('enriched_data', '')}\"\"\"\n",
        "    \n",
        "    return {\"summary\": summary}\n",
        "\n",
        "# Build enrichment subgraph\n",
        "enrichment_builder = StateGraph(EnrichmentState)\n",
        "enrichment_builder.add_node(\"enrich\", enrich_data)\n",
        "enrichment_builder.add_node(\"summarize\", create_summary)\n",
        "enrichment_builder.add_edge(START, \"enrich\")\n",
        "enrichment_builder.add_edge(\"enrich\", \"summarize\")\n",
        "enrichment_builder.add_edge(\"summarize\", END)\n",
        "enrichment_subgraph = enrichment_builder.compile()\n",
        "\n",
        "print(\"‚úì Enrichment subgraph created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-22",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create parent pipeline that uses both subgraphs\n",
        "class PipelineState(TypedDict):\n",
        "    raw_data: str\n",
        "    extracted_entities: list[str]\n",
        "    extracted_keywords: list[str]\n",
        "    enriched_data: str\n",
        "    summary: str\n",
        "    pipeline_result: str\n",
        "\n",
        "def prepare_pipeline(state: PipelineState) -> PipelineState:\n",
        "    \"\"\"Initialize the pipeline.\"\"\"\n",
        "    print(\"\\nüöÄ Starting data processing pipeline...\\n\")\n",
        "    return {}\n",
        "\n",
        "def finalize_pipeline(state: PipelineState) -> PipelineState:\n",
        "    \"\"\"Finalize pipeline results.\"\"\"\n",
        "    print(\"\\n‚úÖ Pipeline complete!\\n\")\n",
        "    \n",
        "    result = f\"\"\"Pipeline Processing Complete\n",
        "{'='*50}\n",
        "\n",
        "Extracted Entities:\n",
        "{', '.join(state.get('extracted_entities', []))}\n",
        "\n",
        "Key Topics:\n",
        "{', '.join(state.get('extracted_keywords', []))}\n",
        "\n",
        "{state.get('summary', '')}\n",
        "\"\"\"\n",
        "    \n",
        "    return {\"pipeline_result\": result}\n",
        "\n",
        "# Build the pipeline\n",
        "pipeline_builder = StateGraph(PipelineState)\n",
        "\n",
        "# Add nodes including both subgraphs\n",
        "pipeline_builder.add_node(\"prepare\", prepare_pipeline)\n",
        "pipeline_builder.add_node(\"extract\", extraction_subgraph)  # First subgraph\n",
        "pipeline_builder.add_node(\"enrich\", enrichment_subgraph)   # Second subgraph\n",
        "pipeline_builder.add_node(\"finalize\", finalize_pipeline)\n",
        "\n",
        "# Add edges\n",
        "pipeline_builder.add_edge(START, \"prepare\")\n",
        "pipeline_builder.add_edge(\"prepare\", \"extract\")\n",
        "pipeline_builder.add_edge(\"extract\", \"enrich\")\n",
        "pipeline_builder.add_edge(\"enrich\", \"finalize\")\n",
        "pipeline_builder.add_edge(\"finalize\", END)\n",
        "\n",
        "# Compile\n",
        "data_pipeline = pipeline_builder.compile()\n",
        "\n",
        "print(\"‚úì Complete data processing pipeline compiled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-23",
      "metadata": {},
      "source": [
        "## Test the Multi-Subgraph Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-24",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the complete pipeline\n",
        "sample_data = \"\"\"Apple Inc. announced a new partnership with Microsoft to develop \n",
        "AI-powered productivity tools. The collaboration will focus on machine learning, \n",
        "natural language processing, and cloud computing technologies. CEO Tim Cook stated \n",
        "that this partnership represents a significant milestone in enterprise software innovation.\"\"\"\n",
        "\n",
        "result = data_pipeline.invoke({\n",
        "    \"raw_data\": sample_data,\n",
        "    \"extracted_entities\": [],\n",
        "    \"extracted_keywords\": [],\n",
        "    \"enriched_data\": \"\",\n",
        "    \"summary\": \"\",\n",
        "    \"pipeline_result\": \"\"\n",
        "})\n",
        "\n",
        "print(result[\"pipeline_result\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-25",
      "metadata": {},
      "source": [
        "## Key Benefits of Subgraphs\n",
        "\n",
        "### 1. Modularity\n",
        "- Each subgraph is self-contained\n",
        "- Easy to understand and maintain\n",
        "- Can be developed and tested independently\n",
        "\n",
        "### 2. Reusability\n",
        "- Use the same subgraph in multiple workflows\n",
        "- Reduce code duplication\n",
        "- Build a library of reusable components\n",
        "\n",
        "### 3. Composability\n",
        "- Combine simple subgraphs into complex workflows\n",
        "- Mix and match components as needed\n",
        "- Scale your applications effectively\n",
        "\n",
        "### 4. Maintainability\n",
        "- Update a subgraph once, affect all uses\n",
        "- Easier debugging and testing\n",
        "- Clear separation of concerns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-26",
      "metadata": {},
      "source": [
        "## State Management Between Parent and Subgraphs\n",
        "\n",
        "Important principles:\n",
        "\n",
        "1. **Shared State Keys**: The parent state must include all keys that the subgraph needs\n",
        "2. **State Updates**: Subgraphs can update any state keys they return\n",
        "3. **State Isolation**: Each subgraph only sees the state keys it defines\n",
        "4. **Type Safety**: Use TypedDict to ensure state compatibility"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-27",
      "metadata": {},
      "source": [
        "## Exercise 1: Create a Translation Subgraph\n",
        "\n",
        "Build a reusable translation subgraph that:\n",
        "1. Detects the source language\n",
        "2. Translates to a target language\n",
        "3. Validates the translation quality\n",
        "\n",
        "Then use it in a parent workflow that processes multiple documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-28",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here!\n",
        "\n",
        "class TranslationState(TypedDict):\n",
        "    text: str\n",
        "    source_language: str\n",
        "    target_language: str\n",
        "    translated_text: str\n",
        "    quality_score: int\n",
        "\n",
        "# TODO: Create nodes for language detection, translation, and validation\n",
        "# TODO: Build the translation subgraph\n",
        "# TODO: Create a parent workflow that uses the translation subgraph\n",
        "# TODO: Test with sample text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-29",
      "metadata": {},
      "source": [
        "## Exercise 2: Build a Document Processing System\n",
        "\n",
        "Create a document processing system with three subgraphs:\n",
        "1. **Parser Subgraph**: Extract structure and metadata\n",
        "2. **Analyzer Subgraph**: Analyze content and sentiment\n",
        "3. **Reporter Subgraph**: Generate reports and summaries\n",
        "\n",
        "Compose them into a complete document processing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cell-30",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here!\n",
        "\n",
        "# TODO: Define states for each subgraph\n",
        "# TODO: Create the parser subgraph\n",
        "# TODO: Create the analyzer subgraph\n",
        "# TODO: Create the reporter subgraph\n",
        "# TODO: Compose them into a parent workflow\n",
        "# TODO: Test with a sample document"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-31",
      "metadata": {},
      "source": [
        "## Best Practices for Subgraphs\n",
        "\n",
        "1. **Single Responsibility**: Each subgraph should have one clear purpose\n",
        "2. **Clear Interfaces**: Define state carefully with TypedDict\n",
        "3. **Independent Testing**: Test subgraphs separately before composition\n",
        "4. **Documentation**: Document what each subgraph does and what state it requires\n",
        "5. **Error Handling**: Include error handling within subgraphs\n",
        "6. **State Minimization**: Only pass the state fields that are truly needed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-32",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "1. ‚úÖ What subgraphs are and why they're useful\n",
        "2. ‚úÖ How to create reusable graph components\n",
        "3. ‚úÖ How to compose subgraphs into larger workflows\n",
        "4. ‚úÖ State management between parent and child graphs\n",
        "5. ‚úÖ Best practices for building modular applications\n",
        "6. ‚úÖ Creating complex pipelines by combining simple subgraphs\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Continue to **Topic 7: Persistence** to learn how to save and restore graph state across sessions!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
