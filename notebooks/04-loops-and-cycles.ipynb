{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 4: Loops and Cycles\n",
    "\n",
    "Master iterative workflows by creating loops and cycles in your graphs. Learn how to build self-improving systems that can iterate until a condition is met.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Create cyclic graphs with loops\n",
    "- Implement iteration limits to prevent infinite loops\n",
    "- Build self-correcting workflows\n",
    "- Use state to control loop termination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import getpass\n",
    "from typing import TypedDict, Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "if \"ANTHROPIC_API_KEY\" not in os.environ:\n",
    "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key: \")\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-sonnet-4-20250514\")\n",
    "print(\"‚úì Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Loops in LangGraph\n",
    "\n",
    "Loops allow a graph to revisit nodes multiple times until a condition is met. This is perfect for:\n",
    "- Iterative refinement\n",
    "- Self-correction\n",
    "- Retry logic\n",
    "- Progressive improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Code Review Loop\n",
    "\n",
    "Let's build a system that iteratively reviews and improves code until it meets quality standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our state\n",
    "class CodeReviewState(TypedDict):\n",
    "    code: str\n",
    "    review_feedback: str\n",
    "    quality_score: int\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "\n",
    "print(\"‚úì CodeReviewState defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_code(state: CodeReviewState) -> CodeReviewState:\n",
    "    \"\"\"Review code and provide quality score and feedback.\"\"\"\n",
    "    print(f\"\\nüîç Review iteration {state['iteration'] + 1}...\")\n",
    "    \n",
    "    prompt = f\"\"\"Review this Python code and rate its quality from 1-10:\n",
    "\n",
    "CODE:\n",
    "```python\n",
    "{state['code']}\n",
    "```\n",
    "\n",
    "Provide:\n",
    "1. Quality Score (1-10)\n",
    "2. Specific improvements needed\n",
    "3. Best practices violations\n",
    "\n",
    "Format your response as:\n",
    "Score: [number]\n",
    "Feedback: [detailed feedback]\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    content = response.content\n",
    "    \n",
    "    # Extract score\n",
    "    score = 5\n",
    "    for line in content.split('\\n'):\n",
    "        if 'Score:' in line or 'score:' in line:\n",
    "            try:\n",
    "                score = int(''.join(filter(str.isdigit, line)))\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"   Quality Score: {score}/10\")\n",
    "    \n",
    "    return {\n",
    "        \"review_feedback\": content,\n",
    "        \"quality_score\": score,\n",
    "        \"iteration\": state['iteration'] + 1\n",
    "    }\n",
    "\n",
    "def improve_code(state: CodeReviewState) -> CodeReviewState:\n",
    "    \"\"\"Improve code based on review feedback.\"\"\"\n",
    "    print(\"‚ú® Improving code based on feedback...\")\n",
    "    \n",
    "    prompt = f\"\"\"Improve this code based on the review feedback:\n",
    "\n",
    "CURRENT CODE:\n",
    "```python\n",
    "{state['code']}\n",
    "```\n",
    "\n",
    "REVIEW FEEDBACK:\n",
    "{state['review_feedback']}\n",
    "\n",
    "Provide ONLY the improved code, no explanations.\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    # Extract code from response\n",
    "    improved_code = response.content\n",
    "    if '```python' in improved_code:\n",
    "        improved_code = improved_code.split('```python')[1].split('```')[0].strip()\n",
    "    elif '```' in improved_code:\n",
    "        improved_code = improved_code.split('```')[1].split('```')[0].strip()\n",
    "    \n",
    "    return {\"code\": improved_code}\n",
    "\n",
    "print(\"‚úì Review and improve nodes created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Key: Conditional Routing for Loops\n",
    "\n",
    "The router function decides whether to continue looping or exit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: CodeReviewState) -> Literal[\"improve\", \"end\"]:\n",
    "    \"\"\"Decide whether to continue improving or finish.\"\"\"\n",
    "    \n",
    "    # Stop if quality is good enough\n",
    "    if state['quality_score'] >= 8:\n",
    "        print(\"‚úÖ Quality threshold met! Finishing...\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # Stop if max iterations reached\n",
    "    if state['iteration'] >= state['max_iterations']:\n",
    "        print(\"‚ö†Ô∏è  Max iterations reached. Finishing...\")\n",
    "        return \"end\"\n",
    "    \n",
    "    # Continue improving\n",
    "    print(\"üîÑ Continuing iteration...\")\n",
    "    return \"improve\"\n",
    "\n",
    "print(\"‚úì Router function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Cyclic Graph\n",
    "\n",
    "Notice how we create a loop by routing back to the review node:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "graph_builder = StateGraph(CodeReviewState)\n",
    "\n",
    "# Add nodes\n",
    "graph_builder.add_node(\"review\", review_code)\n",
    "graph_builder.add_node(\"improve\", improve_code)\n",
    "\n",
    "# Start with review\n",
    "graph_builder.add_edge(START, \"review\")\n",
    "\n",
    "# After review, decide whether to continue or end\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"review\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"improve\": \"improve\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After improving, loop back to review - THIS CREATES THE CYCLE!\n",
    "graph_builder.add_edge(\"improve\", \"review\")\n",
    "\n",
    "# Compile\n",
    "code_review_graph = graph_builder.compile()\n",
    "\n",
    "print(\"‚úì Cyclic code review graph compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(code_review_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(\"Graph structure:\")\n",
    "    print(\"START -> review -> {improve -> review (loop)} -> END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Loop\n",
    "\n",
    "Let's see the iterative improvement in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code that needs improvement\n",
    "initial_code = \"\"\"def calculate(x, y):\n",
    "    return x + y\"\"\"\n",
    "\n",
    "print(\"Initial Code:\")\n",
    "print(initial_code)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Run the iterative improvement\n",
    "result = code_review_graph.invoke({\n",
    "    \"code\": initial_code,\n",
    "    \"review_feedback\": \"\",\n",
    "    \"quality_score\": 0,\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 3\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Final Results:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nIterations: {result['iteration']}\")\n",
    "print(f\"Final Quality Score: {result['quality_score']}/10\")\n",
    "print(f\"\\nImproved Code:\\n{result['code']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Research Paper Refinement\n",
    "\n",
    "Let's build another loop for iteratively refining research findings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    findings: str\n",
    "    critique: str\n",
    "    completeness_score: int\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "\n",
    "def research_topic(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Research the topic and compile findings.\"\"\"\n",
    "    print(f\"\\nüî¨ Research iteration {state['iteration'] + 1}...\")\n",
    "    \n",
    "    if state['iteration'] == 0:\n",
    "        prompt = f\"Research this topic and provide key findings: {state['topic']}\"\n",
    "    else:\n",
    "        prompt = f\"\"\"Expand your research based on this critique:\n",
    "        \n",
    "CURRENT FINDINGS:\n",
    "{state['findings']}\n",
    "\n",
    "CRITIQUE:\n",
    "{state['critique']}\n",
    "\n",
    "Provide improved and expanded findings.\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    \n",
    "    return {\n",
    "        \"findings\": response.content,\n",
    "        \"iteration\": state['iteration'] + 1\n",
    "    }\n",
    "\n",
    "def critique_research(state: ResearchState) -> ResearchState:\n",
    "    \"\"\"Critique the research for completeness.\"\"\"\n",
    "    print(\"üîç Critiquing research...\")\n",
    "    \n",
    "    prompt = f\"\"\"Rate these research findings for completeness (1-10) and provide critique:\n",
    "\n",
    "{state['findings']}\n",
    "\n",
    "Format:\n",
    "Score: [1-10]\n",
    "Critique: [what's missing or needs improvement]\"\"\"\n",
    "    \n",
    "    response = model.invoke([HumanMessage(content=prompt)])\n",
    "    content = response.content\n",
    "    \n",
    "    # Extract score\n",
    "    score = 5\n",
    "    for line in content.split('\\n'):\n",
    "        if 'Score:' in line or 'score:' in line:\n",
    "            try:\n",
    "                score = int(''.join(filter(str.isdigit, line)))\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"   Completeness Score: {score}/10\")\n",
    "    \n",
    "    return {\n",
    "        \"critique\": content,\n",
    "        \"completeness_score\": score\n",
    "    }\n",
    "\n",
    "def should_continue_research(state: ResearchState) -> Literal[\"research\", \"end\"]:\n",
    "    \"\"\"Decide whether to continue researching.\"\"\"\n",
    "    if state['completeness_score'] >= 8:\n",
    "        print(\"‚úÖ Research is complete!\")\n",
    "        return \"end\"\n",
    "    if state['iteration'] >= state['max_iterations']:\n",
    "        print(\"‚ö†Ô∏è  Max iterations reached.\")\n",
    "        return \"end\"\n",
    "    print(\"üîÑ Continuing research...\")\n",
    "    return \"research\"\n",
    "\n",
    "print(\"‚úì Research nodes and router created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build research graph\n",
    "research_graph_builder = StateGraph(ResearchState)\n",
    "\n",
    "research_graph_builder.add_node(\"research\", research_topic)\n",
    "research_graph_builder.add_node(\"critique\", critique_research)\n",
    "\n",
    "research_graph_builder.add_edge(START, \"research\")\n",
    "research_graph_builder.add_edge(\"research\", \"critique\")\n",
    "\n",
    "# The conditional edge that creates the loop\n",
    "research_graph_builder.add_conditional_edges(\n",
    "    \"critique\",\n",
    "    should_continue_research,\n",
    "    {\n",
    "        \"research\": \"research\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "research_graph = research_graph_builder.compile()\n",
    "\n",
    "print(\"‚úì Research refinement graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the research loop\n",
    "print(\"Starting iterative research process...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "result = research_graph.invoke({\n",
    "    \"topic\": \"The impact of AI on software development\",\n",
    "    \"findings\": \"\",\n",
    "    \"critique\": \"\",\n",
    "    \"completeness_score\": 0,\n",
    "    \"iteration\": 0,\n",
    "    \"max_iterations\": 2\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Research Complete!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nIterations: {result['iteration']}\")\n",
    "print(f\"Completeness Score: {result['completeness_score']}/10\")\n",
    "print(f\"\\nFinal Findings:\\n{result['findings']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Patterns for Loops\n",
    "\n",
    "When building loops in LangGraph, always:\n",
    "\n",
    "1. **Include iteration tracking** in your state\n",
    "2. **Set max iterations** to prevent infinite loops\n",
    "3. **Define clear exit conditions** (quality thresholds, completion criteria)\n",
    "4. **Use conditional edges** to control loop flow\n",
    "5. **Add progress logging** to track iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Build a Self-Correcting Translator\n",
    "\n",
    "Create a translation system that:\n",
    "1. Translates text\n",
    "2. Back-translates to check accuracy\n",
    "3. Improves translation if accuracy is low\n",
    "4. Loops until accuracy is high or max iterations reached\n",
    "\n",
    "Hint: Your state should track the original text, translation, back-translation, accuracy score, and iteration count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here!\n",
    "\n",
    "class TranslationState(TypedDict):\n",
    "    original: str\n",
    "    translation: str\n",
    "    back_translation: str\n",
    "    accuracy_score: int\n",
    "    iteration: int\n",
    "    max_iterations: int\n",
    "\n",
    "# TODO: Define translate node\n",
    "# TODO: Define back_translate node\n",
    "# TODO: Define evaluate_accuracy node\n",
    "# TODO: Define router function\n",
    "# TODO: Build graph with loop\n",
    "# TODO: Test it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. ‚úÖ How to create cyclic graphs with loops\n",
    "2. ‚úÖ Using iteration tracking and limits to control loops\n",
    "3. ‚úÖ Building self-correcting and iterative improvement systems\n",
    "4. ‚úÖ Implementing conditional routing for loop control\n",
    "5. ‚úÖ Creating exit conditions based on quality or iteration limits\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to **Topic 5: Human-in-the-Loop** to learn how to add human approval and interaction to your workflows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
